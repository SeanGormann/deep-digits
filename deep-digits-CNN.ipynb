{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Classification with Convolutional Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset already exists\n",
      "Trainset already exists\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# define path to store data\n",
    "trainset_path = '/Users/seangorman/code-projects/deep-digits/trainset'\n",
    "testset_path = '/Users/seangorman/code-projects/deep-digits/testset'\n",
    "\n",
    "# check if trainset and testset already exist at the specified paths\n",
    "def download_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        data = datasets.MNIST(path, download=True, train=True, transform=transform)\n",
    "        print('Trainset downloaded')\n",
    "        return data\n",
    "    else:\n",
    "        data = datasets.MNIST(path, train=True, transform=transform)\n",
    "        print('Trainset already exists')\n",
    "        return data\n",
    "\n",
    "trainset = download_data(trainset_path)\n",
    "testset = download_data(testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcq0lEQVR4nO3df3DU9b3v8dcCyQqabAwh2UQCBlSo/IinVNJcEbFkCPEeK8h0RO0dcDw40OApoNUbj4K2vTcW71iPDkX/aEk9I6icK1Cxcq8GE0qb4BDhMFTNEG4K4UKCcstuCJIE8rl/MG5dSaDfdTfvJDwfM98Zsvt95/vx2x2e/WaXb3zOOScAAHrZIOsFAAAuTwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGK9gK/r6urS0aNHlZKSIp/PZ70cAIBHzjm1trYqJydHgwb1fJ3T5wJ09OhR5ebmWi8DAPANNTU1aeTIkT0+3+cClJKSIkmapv+sIb4k49UAALw66zq1U+9E/j7vScICtGbNGj333HNqbm5Wfn6+XnrpJU2dOvWSc1/+2G2IL4kAAUB/5XTJt1ES8iGEN954QytWrNCqVav00UcfKT8/X8XFxTp+/HgiDgcA6IcSEqDnn39eixYt0gMPPKAbb7xRL7/8soYNG6bf/OY3iTgcAKAfinuAOjo6VFdXp6Kior8dZNAgFRUVqaam5oL929vbFQ6HozYAwMAX9wB9/vnnOnfunLKysqIez8rKUnNz8wX7l5eXKxAIRDY+AQcAlwfzf4haVlamUCgU2ZqamqyXBADoBXH/FFxGRoYGDx6slpaWqMdbWloUDAYv2N/v98vv98d7GQCAPi7uV0DJycmaMmWKKisrI491dXWpsrJShYWF8T4cAKCfSsi/A1qxYoUWLFig73znO5o6dapeeOEFtbW16YEHHkjE4QAA/VBCAnTPPffos88+08qVK9Xc3KybbrpJ27Ztu+CDCQCAy5fPOeesF/FV4XBYgUBAM3xzuBMCAPRDZ12nqtxmhUIhpaam9rif+afgAACXJwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEEOsFAH3JoKFDPc+4cXkJWEl8vLP132Ka+/6UEs8zR+aP9TwzfH+755m2nGTPM7ueXet5RpI+6TjteWbZtf/J+4F8Pu8zAwBXQAAAEwQIAGAi7gF6+umn5fP5orbx48fH+zAAgH4uIe8BTZgwQe+///7fDjKEt5oAANESUoYhQ4YoGAwm4lsDAAaIhLwHdODAAeXk5GjMmDG6//77dfjw4R73bW9vVzgcjtoAAANf3ANUUFCgiooKbdu2TWvXrlVjY6NuvfVWtba2drt/eXm5AoFAZMvNzY33kgAAfVDcA1RSUqIf/OAHmjx5soqLi/X73/9eJ0+e1Jtvvtnt/mVlZQqFQpGtqakp3ksCAPRBCf90QFpamm644QY1NDR0+7zf75ff70/0MgAAfUzC/x3QqVOndPDgQWVnZyf6UACAfiTuAXr00UdVXV2tv/zlL/rTn/6kuXPnavDgwbr33nvjfSgAQD8W9x/BHTlyRPfee69OnDihESNGaNq0aaqtrdWIESPifSgAQD/mc84560V8VTgcViAQ0AzfHA3xJVkvBxdx5h9v9jzTkeL9onvs0k89zxxd6f3GmJIUGuP9Rpd/WPmvMR1roFl+9DbPMx9W/IPnmT8+8YLnmZp27zeZlaR/+l8Pep7xdXp/jV+/bJfnmb7srOtUldusUCik1NTUHvfjXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImE/0I69H1HHymMae5fFm3wPPP9K1tiOpZnFb1zmIHqtOv0PBPq9H7DT9/sE55npn30XzzPnN4z3POMJI1o9H6v5qt/WxvTsS5HXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABHfDhq6pDMU0t/7OAs8z3x/7u5iONdBMeLfU88zQw0meZ/7ng//D84wkHTqb7nnmr9P+6nlmhLzPYODgCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSCG39+OY5hr/37c8z9zxrPebcN73/DueZ36Y8hfPM7G6aec/eZ658b+1eJ45e6jJ88z9nz3ieUaS0ho6PM8k6aOYjoXLF1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKmOXc/YnnmcE3jPU889akHM8zr88o8TwjSVsr1nqeuSH4meeZzkPNnmdiMeKV2l45DhALroAAACYIEADAhOcA7dixQ3feeadycnLk8/m0efPmqOedc1q5cqWys7M1dOhQFRUV6cCBA/FaLwBggPAcoLa2NuXn52vNmjXdPr969Wq9+OKLevnll7Vr1y5deeWVKi4u1pkzZ77xYgEAA4fnDyGUlJSopKT7N3idc3rhhRf05JNP6q677pIkvfrqq8rKytLmzZs1f/78b7ZaAMCAEdf3gBobG9Xc3KyioqLIY4FAQAUFBaqpqel2pr29XeFwOGoDAAx8cQ1Qc/P5j5ZmZWVFPZ6VlRV57uvKy8sVCAQiW25ubjyXBADoo8w/BVdWVqZQKBTZmpqarJcEAOgFcQ1QMBiUJLW0tEQ93tLSEnnu6/x+v1JTU6M2AMDAF9cA5eXlKRgMqrKyMvJYOBzWrl27VFhYGM9DAQD6Oc+fgjt16pQaGhoiXzc2Nmrv3r1KT0/XqFGjtGzZMv385z/X9ddfr7y8PD311FPKycnRnDlz4rluAEA/5zlAu3fv1u233x75esWKFZKkBQsWqKKiQo899pja2tr00EMP6eTJk5o2bZq2bdumK664In6rBgD0ez7nnLNexFeFw2EFAgHN8M3REF+S9XLQTw0ZHdunKTfu/HfPM5Nf/2fPM9f9yx7PM66jw/MMYOGs61SV26xQKHTR9/XNPwUHALg8ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITnX8cADGSx3Nl63/wXPc9MSPuR55kbFtV5ngH6Mq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUA9LZQ00xzWXuzvE8s2NOiueZWZP/7Hnm47lTPc88+N83eZ6RpNcnjvI8486di+lYuHxxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPA555z1Ir4qHA4rEAhohm+OhviSrJcDXFLzpvGeZ342YYvnmaKhJz3PxOrIuU7PM0se+GfPM0M++MjzDPq+s65TVW6zQqGQUlNTe9yPKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQQ6wUA/V1w7qeeZ1aVLvQ885Ns7/cN3rPgXz3PSNLIwd5vBDy4/ZznmY5ZUzzPJP/vOs8z6Ju4AgIAmCBAAAATngO0Y8cO3XnnncrJyZHP59PmzZujnl+4cKF8Pl/UNnv27HitFwAwQHgOUFtbm/Lz87VmzZoe95k9e7aOHTsW2TZs2PCNFgkAGHg8fwihpKREJSUlF93H7/crGAzGvCgAwMCXkPeAqqqqlJmZqXHjxmnJkiU6ceJEj/u2t7crHA5HbQCAgS/uAZo9e7ZeffVVVVZW6he/+IWqq6tVUlKic+e6/4hmeXm5AoFAZMvNzY33kgAAfVDc/x3Q/PnzI3+eNGmSJk+erLFjx6qqqkozZ868YP+ysjKtWLEi8nU4HCZCAHAZSPjHsMeMGaOMjAw1NDR0+7zf71dqamrUBgAY+BIeoCNHjujEiRPKzs5O9KEAAP2I5x/BnTp1KupqprGxUXv37lV6errS09P1zDPPaN68eQoGgzp48KAee+wxXXfddSouLo7rwgEA/ZvnAO3evVu333575Osv379ZsGCB1q5dq3379um3v/2tTp48qZycHM2aNUs/+9nP5Pf747dqAEC/53POeb/DYQKFw2EFAgHN8M3REJ/3GyICA9WgCeM8zwReOR7TsV4Z/Y7nmSQN9jxz07/92PNM3hO1nmfQu866TlW5zQqFQhd9X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4DE6PpzveeZv06L7VihQ+c8z2QM8n437Pfvf87zzIxhj3qeuX7ZLs8zSDyugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFDDQ8nCh55ngK3WeZw791ymeZyQpY1Dv3Lxz9oeLPc/c8NgezzPO8wR6A1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKfMVfF3zX88zVH5/yPHPHAzs9zzz52G7PM9IfYpiJTairw/vQf6R6HnEdMRwHfRJXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5Gij7v3G3/4HnmyV9XxHSsXx1L9zxTce27MR2rL5tYudjzjH9Yp+eZUT+v8TyDgYMrIACACQIEADDhKUDl5eW6+eablZKSoszMTM2ZM0f19fVR+5w5c0alpaUaPny4rrrqKs2bN08tLS1xXTQAoP/zFKDq6mqVlpaqtrZW7733njo7OzVr1iy1tbVF9lm+fLnefvttbdy4UdXV1Tp69KjuvvvuuC8cANC/efoQwrZt26K+rqioUGZmpurq6jR9+nSFQiH9+te/1vr16/W9731PkrRu3Tp961vfUm1trb77Xe+/bRIAMDB9o/eAQqGQJCk9/fwnh+rq6tTZ2amioqLIPuPHj9eoUaNUU9P9p13a29sVDoejNgDAwBdzgLq6urRs2TLdcsstmjhxoiSpublZycnJSktLi9o3KytLzc3N3X6f8vJyBQKByJabmxvrkgAA/UjMASotLdX+/fv1+uuvf6MFlJWVKRQKRbampqZv9P0AAP1DTP8QdenSpdq6dat27NihkSNHRh4PBoPq6OjQyZMno66CWlpaFAwGu/1efr9ffr8/lmUAAPoxT1dAzjktXbpUmzZt0vbt25WXlxf1/JQpU5SUlKTKysrIY/X19Tp8+LAKCwvjs2IAwIDg6QqotLRU69ev15YtW5SSkhJ5XycQCGjo0KEKBAJ68MEHtWLFCqWnpys1NVUPP/ywCgsL+QQcACCKpwCtXbtWkjRjxoyox9etW6eFCxdKkn75y19q0KBBmjdvntrb21VcXKxf/epXcVksAGDg8DnnnPUiviocDisQCGiGb46G+JKsl4OL6Jp2k+eZg/OTPc9kjfnc80zlpA2eZ/q6Ce+Wep5JHXEqpmNl3/N/PM+4jo6YjoWB56zrVJXbrFAopNTU1B73415wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHTb0RF3+W76UbPM8cLer5b7cWMvLfR88z+sb+L6Vh92YTfLfU8c1W297tU3/j0//U8c/boMc8zktSnbpGPAYsrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcj7SWHVxZ6nrniM+/HueWBOs8zb2X/wfuB+rh9HYNjmvvpt7/neebGtGbPM2cPNXmf8TwB9G1cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZaS8Z88pBzzMbd7+dgJXEz4z/uN/zTMbCk55n3Jkznmc0+hrvM5K6QvXeh0LhmI4FXO64AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAz0l5ytuW455m5uQUJWEn8XK0GzzPnErCObv05hpuKAuhVXAEBAEwQIACACU8BKi8v180336yUlBRlZmZqzpw5qq+P/lHHjBkz5PP5orbFixfHddEAgP7PU4Cqq6tVWlqq2tpavffee+rs7NSsWbPU1tYWtd+iRYt07NixyLZ69eq4LhoA0P95+hDCtm3bor6uqKhQZmam6urqNH369Mjjw4YNUzAYjM8KAQAD0jd6DygUCkmS0tPTox5/7bXXlJGRoYkTJ6qsrEynT5/u8Xu0t7crHA5HbQCAgS/mj2F3dXVp2bJluuWWWzRx4sTI4/fdd59Gjx6tnJwc7du3T48//rjq6+v11ltvdft9ysvL9cwzz8S6DABAP+VzzrlYBpcsWaJ3331XO3fu1MiRI3vcb/v27Zo5c6YaGho0duzYC55vb29Xe3t75OtwOKzc3FzN8M3REF9SLEsDABg66zpV5TYrFAopNTW1x/1iugJaunSptm7dqh07dlw0PpJUUHD+H1P2FCC/3y+/3x/LMgAA/ZinADnn9PDDD2vTpk2qqqpSXl7eJWf27t0rScrOzo5pgQCAgclTgEpLS7V+/Xpt2bJFKSkpam5uliQFAgENHTpUBw8e1Pr163XHHXdo+PDh2rdvn5YvX67p06dr8uTJCfkPAAD0T57eA/L5fN0+vm7dOi1cuFBNTU364Q9/qP3796utrU25ubmaO3eunnzyyYv+HPCrwuGwAoEA7wEBQD+VkPeALtWq3NxcVVdXe/mWAIDLFPeCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGK9gK9zzkmSzrpO45UAAGLx5d/fX/593pM+F6DW1lZJ0k69I1187QCAPqy1tVWBQKDH533uUonqZV1dXTp69KhSUlLk8/minguHw8rNzVVTU5NSU1ONVmiP83Ae5+E8zsN5nIfz+sJ5cM6ptbVVOTk5GjSo53d6+twV0KBBgzRy5MiL7pOamnpZv8C+xHk4j/NwHufhPM7Dedbn4WJXPl/iQwgAABMECABgol8FyO/3a9WqVfL7/dZLMcV5OI/zcB7n4TzOw3n96Tz0uQ8hAAAuD/3qCggAMHAQIACACQIEADBBgAAAJvpNgNasWaNrr71WV1xxhQoKCvThhx9aL6nXPf300/L5fFHb+PHjrZeVcDt27NCdd96pnJwc+Xw+bd68Oep555xWrlyp7OxsDR06VEVFRTpw4IDNYhPoUudh4cKFF7w+Zs+ebbPYBCkvL9fNN9+slJQUZWZmas6cOaqvr4/a58yZMyotLdXw4cN11VVXad68eWppaTFacWL8PedhxowZF7weFi9ebLTi7vWLAL3xxhtasWKFVq1apY8++kj5+fkqLi7W8ePHrZfW6yZMmKBjx45Ftp07d1ovKeHa2tqUn5+vNWvWdPv86tWr9eKLL+rll1/Wrl27dOWVV6q4uFhnzpzp5ZUm1qXOgyTNnj076vWxYcOGXlxh4lVXV6u0tFS1tbV677331NnZqVmzZqmtrS2yz/Lly/X2229r48aNqq6u1tGjR3X33Xcbrjr+/p7zIEmLFi2Kej2sXr3aaMU9cP3A1KlTXWlpaeTrc+fOuZycHFdeXm64qt63atUql5+fb70MU5Lcpk2bIl93dXW5YDDonnvuuchjJ0+edH6/323YsMFghb3j6+fBOecWLFjg7rrrLpP1WDl+/LiT5Kqrq51z5/+3T0pKchs3bozs88knnzhJrqamxmqZCff18+Ccc7fddpv78Y9/bLeov0OfvwLq6OhQXV2dioqKIo8NGjRIRUVFqqmpMVyZjQMHDignJ0djxozR/fffr8OHD1svyVRjY6Oam5ujXh+BQEAFBQWX5eujqqpKmZmZGjdunJYsWaITJ05YLymhQqGQJCk9PV2SVFdXp87OzqjXw/jx4zVq1KgB/Xr4+nn40muvvaaMjAxNnDhRZWVlOn36tMXyetTnbkb6dZ9//rnOnTunrKysqMezsrL06aefGq3KRkFBgSoqKjRu3DgdO3ZMzzzzjG699Vbt379fKSkp1ssz0dzcLEndvj6+fO5yMXv2bN19993Ky8vTwYMH9cQTT6ikpEQ1NTUaPHiw9fLirqurS8uWLdMtt9yiiRMnSjr/ekhOTlZaWlrUvgP59dDdeZCk++67T6NHj1ZOTo727dunxx9/XPX19XrrrbcMVxutzwcIf1NSUhL58+TJk1VQUKDRo0frzTff1IMPPmi4MvQF8+fPj/x50qRJmjx5ssaOHauqqirNnDnTcGWJUVpaqv37918W74NeTE/n4aGHHor8edKkScrOztbMmTN18OBBjR07treX2a0+/yO4jIwMDR48+IJPsbS0tCgYDBqtqm9IS0vTDTfcoIaGBuulmPnyNcDr40JjxoxRRkbGgHx9LF26VFu3btUHH3wQ9etbgsGgOjo6dPLkyaj9B+rroafz0J2CggJJ6lOvhz4foOTkZE2ZMkWVlZWRx7q6ulRZWanCwkLDldk7deqUDh48qOzsbOulmMnLy1MwGIx6fYTDYe3ateuyf30cOXJEJ06cGFCvD+ecli5dqk2bNmn79u3Ky8uLen7KlClKSkqKej3U19fr8OHDA+r1cKnz0J29e/dKUt96PVh/CuLv8frrrzu/3+8qKircxx9/7B566CGXlpbmmpubrZfWqx555BFXVVXlGhsb3R//+EdXVFTkMjIy3PHjx62XllCtra1uz549bs+ePU6Se/75592ePXvcoUOHnHPOPfvssy4tLc1t2bLF7du3z911110uLy/PffHFF8Yrj6+LnYfW1lb36KOPupqaGtfY2Ojef/999+1vf9tdf/317syZM9ZLj5slS5a4QCDgqqqq3LFjxyLb6dOnI/ssXrzYjRo1ym3fvt3t3r3bFRYWusLCQsNVx9+lzkNDQ4P76U9/6nbv3u0aGxvdli1b3JgxY9z06dONVx6tXwTIOedeeuklN2rUKJecnOymTp3qamtrrZfU6+655x6XnZ3tkpOT3TXXXOPuuece19DQYL2shPvggw+cpAu2BQsWOOfOfxT7qaeecllZWc7v97uZM2e6+vp620UnwMXOw+nTp92sWbPciBEjXFJSkhs9erRbtGjRgPs/ad3990ty69ati+zzxRdfuB/96Efu6quvdsOGDXNz5851x44ds1t0AlzqPBw+fNhNnz7dpaenO7/f76677jr3k5/8xIVCIduFfw2/jgEAYKLPvwcEABiYCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/x98/g07mo/ShwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = trainset[0]\n",
    "\n",
    "# convert the tensor back to an image\n",
    "image = transforms.ToPILImage()(image)\n",
    "\n",
    "# display the image\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.003\n",
    "dropout = 0.2\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: [64, 1, 28, 28]\n",
      "  y: [64]\n",
      "Sample point:\n",
      "  X: tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.6000, -0.1059, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.0588,  0.9922, -0.0902, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.1451,  0.9922, -0.3647, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.9137,  0.7255,  0.9922, -0.5294, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.2863,  0.9922,  0.6784, -0.8196, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.0118,  0.9922,  0.0745, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9216,\n",
      "           0.6706,  0.9373, -0.6157, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2863,\n",
      "           0.9922,  0.3569, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0196,\n",
      "           0.9922, -0.0745, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3647,\n",
      "           0.9451, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8118,  0.8431,\n",
      "           0.3569, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2941,  0.9922,\n",
      "           0.0118, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.1294,  0.9529,\n",
      "          -0.5686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.8118,  0.8510,  0.3569,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.0667,  0.9922, -0.0745,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9686,  0.3804,  0.9686, -0.7176,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.5216,  0.9922,  0.1216, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.1216,  1.0000, -0.0745, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.1294,  1.0000, -0.7333, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.5686,  0.4902, -0.9137, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])\n",
      "  y: 1\n"
     ]
    }
   ],
   "source": [
    "# define the trainloader and testloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Visualising data batching\n",
    "batch_X, batch_y = next(iter(trainloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {list(batch_X.size())}\\n\"\n",
    "    f\"  y: {list(batch_y.size())}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define evaluation metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define evaluation function \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics(y_true, y_pred, classes):\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199882 Model parameters\n"
     ]
    }
   ],
   "source": [
    "# Construct a CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)     #input of 1, output of 32 filters, kernel size of 3x3, stride of 1 (moves 1 pixel at a time)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)    #input of 32, output of 64 filters, kernel size of 3x3, stride of 1 (moves 1 pixel at a time)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(9216, 128)         #input of 9216 (Output of conv2, then pooled), output of 128\n",
    "        self.fc2 = nn.Linear(128, 10)  \n",
    "\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)       #x enters of shape (batch_size, 1, 28, 28)\n",
    "        x = F.relu(x)           #x is of shape (batch_size, 32, 26, 26), 3x3 kernels leaves behind 2 pixels at each edge \n",
    "        x = self.conv2(x)   \n",
    "        x = F.relu(x)           #x is of shape (batch_size, 64, 24, 24)\n",
    "        x = F.max_pool2d(x, 2)  #x is of shape (batch_size, 64, 12, 12)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1) #after flattening x is of shape (batch_size, 9216 (64*12*12))) \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)         #x is of shape (batch_size, 10), where each element in \"10\" is the probability of the image being a digit 0-9\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "# print model parameters\n",
    "print(sum(p.numel() for p in model.parameters()), 'Model parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.136033 \tTraining Accuracy: 0.958817\n",
      "Epoch: 2 \tTraining Loss: 0.058782 \tTraining Accuracy: 0.982117\n",
      "Epoch: 3 \tTraining Loss: 0.041056 \tTraining Accuracy: 0.987667\n",
      "Epoch: 4 \tTraining Loss: 0.034460 \tTraining Accuracy: 0.989433\n",
      "Epoch: 5 \tTraining Loss: 0.030347 \tTraining Accuracy: 0.990217\n",
      "Epoch: 6 \tTraining Loss: 0.026257 \tTraining Accuracy: 0.992000\n",
      "Epoch: 7 \tTraining Loss: 0.023562 \tTraining Accuracy: 0.992533\n",
      "Epoch: 8 \tTraining Loss: 0.022522 \tTraining Accuracy: 0.992750\n",
      "Epoch: 9 \tTraining Loss: 0.019690 \tTraining Accuracy: 0.993850\n",
      "Epoch: 10 \tTraining Loss: 0.016622 \tTraining Accuracy: 0.994983\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)             #make preds in forward pass\n",
    "        loss = criterion(outputs, labels)   #calculate loss\n",
    "        loss.backward()                     #backpropagate loss\n",
    "        optimizer.step()                    #update weights\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)  #_ is a throwaway variable (max value in each batch), prediction is the index of the max value\n",
    "        train_accuracy += (prediction == labels).sum().item()\n",
    "    losses.append(train_loss)\n",
    "    train_loss = train_loss / len(trainloader.dataset)\n",
    "    train_accuracy = train_accuracy / len(trainloader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(epoch+1, train_loss, train_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "losses = [0.136033, 0.0587282, 0.041056, 0.034460, 0.030347, 0.026257, 0.023562, 0.022522, 0.019690, 0.016622]\n",
    "plt.plot(losses)\n",
    "plt.title('Loss over 10 epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('CNN-loss-over-time.png', dpi = 120)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000000 \tTest Accuracy: 0.001067\n",
      "Test Loss: 0.000002 \tTest Accuracy: 0.002133\n",
      "Test Loss: 0.000004 \tTest Accuracy: 0.003200\n",
      "Test Loss: 0.000005 \tTest Accuracy: 0.004267\n",
      "Test Loss: 0.000005 \tTest Accuracy: 0.005333\n",
      "Test Loss: 0.000027 \tTest Accuracy: 0.006383\n",
      "Test Loss: 0.000028 \tTest Accuracy: 0.007450\n",
      "Test Loss: 0.000029 \tTest Accuracy: 0.008517\n",
      "Test Loss: 0.000030 \tTest Accuracy: 0.009583\n",
      "Test Loss: 0.000030 \tTest Accuracy: 0.010650\n",
      "Test Loss: 0.000032 \tTest Accuracy: 0.011717\n",
      "Test Loss: 0.000038 \tTest Accuracy: 0.012783\n",
      "Test Loss: 0.000038 \tTest Accuracy: 0.013850\n",
      "Test Loss: 0.000038 \tTest Accuracy: 0.014917\n",
      "Test Loss: 0.000039 \tTest Accuracy: 0.015983\n",
      "Test Loss: 0.000040 \tTest Accuracy: 0.017050\n",
      "Test Loss: 0.000044 \tTest Accuracy: 0.018117\n",
      "Test Loss: 0.000044 \tTest Accuracy: 0.019183\n",
      "Test Loss: 0.000047 \tTest Accuracy: 0.020250\n",
      "Test Loss: 0.000048 \tTest Accuracy: 0.021317\n",
      "Test Loss: 0.000048 \tTest Accuracy: 0.022383\n",
      "Test Loss: 0.000051 \tTest Accuracy: 0.023450\n",
      "Test Loss: 0.000051 \tTest Accuracy: 0.024517\n",
      "Test Loss: 0.000052 \tTest Accuracy: 0.025583\n",
      "Test Loss: 0.000055 \tTest Accuracy: 0.026650\n",
      "Test Loss: 0.000057 \tTest Accuracy: 0.027717\n",
      "Test Loss: 0.000068 \tTest Accuracy: 0.028783\n",
      "Test Loss: 0.000068 \tTest Accuracy: 0.029850\n",
      "Test Loss: 0.000069 \tTest Accuracy: 0.030917\n",
      "Test Loss: 0.000071 \tTest Accuracy: 0.031983\n",
      "Test Loss: 0.000071 \tTest Accuracy: 0.033050\n",
      "Test Loss: 0.000071 \tTest Accuracy: 0.034117\n",
      "Test Loss: 0.000071 \tTest Accuracy: 0.035183\n",
      "Test Loss: 0.000071 \tTest Accuracy: 0.036250\n",
      "Test Loss: 0.000073 \tTest Accuracy: 0.037317\n",
      "Test Loss: 0.000073 \tTest Accuracy: 0.038383\n",
      "Test Loss: 0.000084 \tTest Accuracy: 0.039450\n",
      "Test Loss: 0.000084 \tTest Accuracy: 0.040517\n",
      "Test Loss: 0.000093 \tTest Accuracy: 0.041583\n",
      "Test Loss: 0.000093 \tTest Accuracy: 0.042650\n",
      "Test Loss: 0.000093 \tTest Accuracy: 0.043717\n",
      "Test Loss: 0.000093 \tTest Accuracy: 0.044783\n",
      "Test Loss: 0.000095 \tTest Accuracy: 0.045850\n",
      "Test Loss: 0.000096 \tTest Accuracy: 0.046917\n",
      "Test Loss: 0.000099 \tTest Accuracy: 0.047983\n",
      "Test Loss: 0.000100 \tTest Accuracy: 0.049050\n",
      "Test Loss: 0.000100 \tTest Accuracy: 0.050117\n",
      "Test Loss: 0.000101 \tTest Accuracy: 0.051183\n",
      "Test Loss: 0.000116 \tTest Accuracy: 0.052250\n",
      "Test Loss: 0.000116 \tTest Accuracy: 0.053317\n",
      "Test Loss: 0.000116 \tTest Accuracy: 0.054383\n",
      "Test Loss: 0.000117 \tTest Accuracy: 0.055450\n",
      "Test Loss: 0.000121 \tTest Accuracy: 0.056517\n",
      "Test Loss: 0.000124 \tTest Accuracy: 0.057583\n",
      "Test Loss: 0.000126 \tTest Accuracy: 0.058650\n",
      "Test Loss: 0.000127 \tTest Accuracy: 0.059717\n",
      "Test Loss: 0.000127 \tTest Accuracy: 0.060783\n",
      "Test Loss: 0.000128 \tTest Accuracy: 0.061850\n",
      "Test Loss: 0.000131 \tTest Accuracy: 0.062917\n",
      "Test Loss: 0.000131 \tTest Accuracy: 0.063983\n",
      "Test Loss: 0.000133 \tTest Accuracy: 0.065050\n",
      "Test Loss: 0.000133 \tTest Accuracy: 0.066117\n",
      "Test Loss: 0.000133 \tTest Accuracy: 0.067183\n",
      "Test Loss: 0.000134 \tTest Accuracy: 0.068250\n",
      "Test Loss: 0.000203 \tTest Accuracy: 0.069300\n",
      "Test Loss: 0.000203 \tTest Accuracy: 0.070367\n",
      "Test Loss: 0.000203 \tTest Accuracy: 0.071433\n",
      "Test Loss: 0.000203 \tTest Accuracy: 0.072500\n",
      "Test Loss: 0.000204 \tTest Accuracy: 0.073567\n",
      "Test Loss: 0.000205 \tTest Accuracy: 0.074633\n",
      "Test Loss: 0.000206 \tTest Accuracy: 0.075700\n",
      "Test Loss: 0.000214 \tTest Accuracy: 0.076767\n",
      "Test Loss: 0.000215 \tTest Accuracy: 0.077833\n",
      "Test Loss: 0.000234 \tTest Accuracy: 0.078883\n",
      "Test Loss: 0.000291 \tTest Accuracy: 0.079917\n",
      "Test Loss: 0.000291 \tTest Accuracy: 0.080983\n",
      "Test Loss: 0.000292 \tTest Accuracy: 0.082050\n",
      "Test Loss: 0.000293 \tTest Accuracy: 0.083117\n",
      "Test Loss: 0.000293 \tTest Accuracy: 0.084183\n",
      "Test Loss: 0.000294 \tTest Accuracy: 0.085250\n",
      "Test Loss: 0.000294 \tTest Accuracy: 0.086317\n",
      "Test Loss: 0.000297 \tTest Accuracy: 0.087383\n",
      "Test Loss: 0.000297 \tTest Accuracy: 0.088450\n",
      "Test Loss: 0.000298 \tTest Accuracy: 0.089517\n",
      "Test Loss: 0.000298 \tTest Accuracy: 0.090583\n",
      "Test Loss: 0.000298 \tTest Accuracy: 0.091650\n",
      "Test Loss: 0.000298 \tTest Accuracy: 0.092717\n",
      "Test Loss: 0.000300 \tTest Accuracy: 0.093783\n",
      "Test Loss: 0.000305 \tTest Accuracy: 0.094850\n",
      "Test Loss: 0.000306 \tTest Accuracy: 0.095917\n",
      "Test Loss: 0.000307 \tTest Accuracy: 0.096983\n",
      "Test Loss: 0.000308 \tTest Accuracy: 0.098050\n",
      "Test Loss: 0.000309 \tTest Accuracy: 0.099117\n",
      "Test Loss: 0.000310 \tTest Accuracy: 0.100183\n",
      "Test Loss: 0.000310 \tTest Accuracy: 0.101250\n",
      "Test Loss: 0.000313 \tTest Accuracy: 0.102317\n",
      "Test Loss: 0.000314 \tTest Accuracy: 0.103383\n",
      "Test Loss: 0.000314 \tTest Accuracy: 0.104450\n",
      "Test Loss: 0.000319 \tTest Accuracy: 0.105517\n",
      "Test Loss: 0.000324 \tTest Accuracy: 0.106583\n",
      "Test Loss: 0.000325 \tTest Accuracy: 0.107650\n",
      "Test Loss: 0.000326 \tTest Accuracy: 0.108717\n",
      "Test Loss: 0.000326 \tTest Accuracy: 0.109783\n",
      "Test Loss: 0.000385 \tTest Accuracy: 0.110833\n",
      "Test Loss: 0.000385 \tTest Accuracy: 0.111900\n",
      "Test Loss: 0.000386 \tTest Accuracy: 0.112967\n",
      "Test Loss: 0.000426 \tTest Accuracy: 0.114017\n",
      "Test Loss: 0.000431 \tTest Accuracy: 0.115083\n",
      "Test Loss: 0.000431 \tTest Accuracy: 0.116150\n",
      "Test Loss: 0.000432 \tTest Accuracy: 0.117217\n",
      "Test Loss: 0.000433 \tTest Accuracy: 0.118283\n",
      "Test Loss: 0.000435 \tTest Accuracy: 0.119350\n",
      "Test Loss: 0.000439 \tTest Accuracy: 0.120417\n",
      "Test Loss: 0.000468 \tTest Accuracy: 0.121467\n",
      "Test Loss: 0.000468 \tTest Accuracy: 0.122533\n",
      "Test Loss: 0.000468 \tTest Accuracy: 0.123600\n",
      "Test Loss: 0.000469 \tTest Accuracy: 0.124667\n",
      "Test Loss: 0.000469 \tTest Accuracy: 0.125733\n",
      "Test Loss: 0.000469 \tTest Accuracy: 0.126800\n",
      "Test Loss: 0.000475 \tTest Accuracy: 0.127867\n",
      "Test Loss: 0.000501 \tTest Accuracy: 0.128917\n",
      "Test Loss: 0.000504 \tTest Accuracy: 0.129983\n",
      "Test Loss: 0.000504 \tTest Accuracy: 0.131050\n",
      "Test Loss: 0.000506 \tTest Accuracy: 0.132117\n",
      "Test Loss: 0.000506 \tTest Accuracy: 0.133183\n",
      "Test Loss: 0.000506 \tTest Accuracy: 0.134250\n",
      "Test Loss: 0.000506 \tTest Accuracy: 0.135317\n",
      "Test Loss: 0.000634 \tTest Accuracy: 0.136333\n",
      "Test Loss: 0.000635 \tTest Accuracy: 0.137400\n",
      "Test Loss: 0.000635 \tTest Accuracy: 0.138467\n",
      "Test Loss: 0.000646 \tTest Accuracy: 0.139533\n",
      "Test Loss: 0.000646 \tTest Accuracy: 0.140600\n",
      "Test Loss: 0.000646 \tTest Accuracy: 0.141667\n",
      "Test Loss: 0.000646 \tTest Accuracy: 0.142733\n",
      "Test Loss: 0.000647 \tTest Accuracy: 0.143800\n",
      "Test Loss: 0.000648 \tTest Accuracy: 0.144867\n",
      "Test Loss: 0.000648 \tTest Accuracy: 0.145933\n",
      "Test Loss: 0.000654 \tTest Accuracy: 0.147000\n",
      "Test Loss: 0.000655 \tTest Accuracy: 0.148067\n",
      "Test Loss: 0.000655 \tTest Accuracy: 0.149133\n",
      "Test Loss: 0.000656 \tTest Accuracy: 0.150200\n",
      "Test Loss: 0.000656 \tTest Accuracy: 0.151267\n",
      "Test Loss: 0.000708 \tTest Accuracy: 0.152317\n",
      "Test Loss: 0.000710 \tTest Accuracy: 0.153383\n",
      "Test Loss: 0.000718 \tTest Accuracy: 0.154450\n",
      "Test Loss: 0.000718 \tTest Accuracy: 0.155517\n",
      "Test Loss: 0.000718 \tTest Accuracy: 0.156583\n",
      "Test Loss: 0.000719 \tTest Accuracy: 0.157650\n",
      "Test Loss: 0.000719 \tTest Accuracy: 0.158717\n",
      "Test Loss: 0.000720 \tTest Accuracy: 0.159783\n",
      "Test Loss: 0.000720 \tTest Accuracy: 0.160850\n",
      "Test Loss: 0.000726 \tTest Accuracy: 0.161917\n",
      "Test Loss: 0.000726 \tTest Accuracy: 0.162983\n",
      "Test Loss: 0.000727 \tTest Accuracy: 0.164050\n",
      "Test Loss: 0.000727 \tTest Accuracy: 0.165117\n",
      "Test Loss: 0.000731 \tTest Accuracy: 0.166183\n",
      "Test Loss: 0.000731 \tTest Accuracy: 0.167250\n",
      "Test Loss: 0.000735 \tTest Accuracy: 0.168317\n",
      "Test Loss: 0.000736 \tTest Accuracy: 0.169383\n",
      "Test Loss: 0.000768 \tTest Accuracy: 0.170433\n",
      "Test Loss: 0.000777 \tTest Accuracy: 0.171500\n",
      "Test Loss: 0.000781 \tTest Accuracy: 0.172567\n",
      "Test Loss: 0.000782 \tTest Accuracy: 0.173633\n",
      "Test Loss: 0.000785 \tTest Accuracy: 0.174700\n",
      "Test Loss: 0.000785 \tTest Accuracy: 0.175767\n",
      "Test Loss: 0.000793 \tTest Accuracy: 0.176833\n",
      "Test Loss: 0.000793 \tTest Accuracy: 0.177900\n",
      "Test Loss: 0.000793 \tTest Accuracy: 0.178967\n",
      "Test Loss: 0.000793 \tTest Accuracy: 0.180033\n",
      "Test Loss: 0.000795 \tTest Accuracy: 0.181100\n",
      "Test Loss: 0.000795 \tTest Accuracy: 0.182167\n",
      "Test Loss: 0.000795 \tTest Accuracy: 0.183233\n",
      "Test Loss: 0.000796 \tTest Accuracy: 0.184300\n",
      "Test Loss: 0.000798 \tTest Accuracy: 0.185367\n",
      "Test Loss: 0.000798 \tTest Accuracy: 0.186433\n",
      "Test Loss: 0.000807 \tTest Accuracy: 0.187500\n",
      "Test Loss: 0.000857 \tTest Accuracy: 0.188550\n",
      "Test Loss: 0.000859 \tTest Accuracy: 0.189617\n",
      "Test Loss: 0.000859 \tTest Accuracy: 0.190683\n",
      "Test Loss: 0.000859 \tTest Accuracy: 0.191750\n",
      "Test Loss: 0.000915 \tTest Accuracy: 0.192800\n",
      "Test Loss: 0.000917 \tTest Accuracy: 0.193867\n",
      "Test Loss: 0.000917 \tTest Accuracy: 0.194933\n",
      "Test Loss: 0.000917 \tTest Accuracy: 0.196000\n",
      "Test Loss: 0.000919 \tTest Accuracy: 0.197067\n",
      "Test Loss: 0.000921 \tTest Accuracy: 0.198133\n",
      "Test Loss: 0.000946 \tTest Accuracy: 0.199183\n",
      "Test Loss: 0.000946 \tTest Accuracy: 0.200250\n",
      "Test Loss: 0.000952 \tTest Accuracy: 0.201317\n",
      "Test Loss: 0.000952 \tTest Accuracy: 0.202383\n",
      "Test Loss: 0.000953 \tTest Accuracy: 0.203450\n",
      "Test Loss: 0.000954 \tTest Accuracy: 0.204517\n",
      "Test Loss: 0.000954 \tTest Accuracy: 0.205583\n",
      "Test Loss: 0.000957 \tTest Accuracy: 0.206650\n",
      "Test Loss: 0.000958 \tTest Accuracy: 0.207717\n",
      "Test Loss: 0.000959 \tTest Accuracy: 0.208783\n",
      "Test Loss: 0.000959 \tTest Accuracy: 0.209850\n",
      "Test Loss: 0.000960 \tTest Accuracy: 0.210917\n",
      "Test Loss: 0.000960 \tTest Accuracy: 0.211983\n",
      "Test Loss: 0.000961 \tTest Accuracy: 0.213050\n",
      "Test Loss: 0.000962 \tTest Accuracy: 0.214117\n",
      "Test Loss: 0.000962 \tTest Accuracy: 0.215183\n",
      "Test Loss: 0.000963 \tTest Accuracy: 0.216250\n",
      "Test Loss: 0.000963 \tTest Accuracy: 0.217317\n",
      "Test Loss: 0.000963 \tTest Accuracy: 0.218383\n",
      "Test Loss: 0.000963 \tTest Accuracy: 0.219450\n",
      "Test Loss: 0.000963 \tTest Accuracy: 0.220517\n",
      "Test Loss: 0.000966 \tTest Accuracy: 0.221583\n",
      "Test Loss: 0.000970 \tTest Accuracy: 0.222650\n",
      "Test Loss: 0.000973 \tTest Accuracy: 0.223717\n",
      "Test Loss: 0.000975 \tTest Accuracy: 0.224783\n",
      "Test Loss: 0.000975 \tTest Accuracy: 0.225850\n",
      "Test Loss: 0.000975 \tTest Accuracy: 0.226917\n",
      "Test Loss: 0.000976 \tTest Accuracy: 0.227983\n",
      "Test Loss: 0.000976 \tTest Accuracy: 0.229050\n",
      "Test Loss: 0.000977 \tTest Accuracy: 0.230117\n",
      "Test Loss: 0.000977 \tTest Accuracy: 0.231183\n",
      "Test Loss: 0.000977 \tTest Accuracy: 0.232250\n",
      "Test Loss: 0.000978 \tTest Accuracy: 0.233317\n",
      "Test Loss: 0.000978 \tTest Accuracy: 0.234383\n",
      "Test Loss: 0.000980 \tTest Accuracy: 0.235450\n",
      "Test Loss: 0.000980 \tTest Accuracy: 0.236517\n",
      "Test Loss: 0.000999 \tTest Accuracy: 0.237567\n",
      "Test Loss: 0.000999 \tTest Accuracy: 0.238633\n",
      "Test Loss: 0.001000 \tTest Accuracy: 0.239700\n",
      "Test Loss: 0.001001 \tTest Accuracy: 0.240767\n",
      "Test Loss: 0.001001 \tTest Accuracy: 0.241833\n",
      "Test Loss: 0.001017 \tTest Accuracy: 0.242900\n",
      "Test Loss: 0.001018 \tTest Accuracy: 0.243967\n",
      "Test Loss: 0.001018 \tTest Accuracy: 0.245033\n",
      "Test Loss: 0.001018 \tTest Accuracy: 0.246100\n",
      "Test Loss: 0.001018 \tTest Accuracy: 0.247167\n",
      "Test Loss: 0.001019 \tTest Accuracy: 0.248233\n",
      "Test Loss: 0.001019 \tTest Accuracy: 0.249300\n",
      "Test Loss: 0.001019 \tTest Accuracy: 0.250367\n",
      "Test Loss: 0.001020 \tTest Accuracy: 0.251433\n",
      "Test Loss: 0.001020 \tTest Accuracy: 0.252500\n",
      "Test Loss: 0.001020 \tTest Accuracy: 0.253567\n",
      "Test Loss: 0.001020 \tTest Accuracy: 0.254633\n",
      "Test Loss: 0.001020 \tTest Accuracy: 0.255700\n",
      "Test Loss: 0.001030 \tTest Accuracy: 0.256767\n",
      "Test Loss: 0.001032 \tTest Accuracy: 0.257833\n",
      "Test Loss: 0.001087 \tTest Accuracy: 0.258883\n",
      "Test Loss: 0.001087 \tTest Accuracy: 0.259950\n",
      "Test Loss: 0.001088 \tTest Accuracy: 0.261017\n",
      "Test Loss: 0.001188 \tTest Accuracy: 0.262067\n",
      "Test Loss: 0.001196 \tTest Accuracy: 0.263133\n",
      "Test Loss: 0.001196 \tTest Accuracy: 0.264200\n",
      "Test Loss: 0.001196 \tTest Accuracy: 0.265267\n",
      "Test Loss: 0.001196 \tTest Accuracy: 0.266333\n",
      "Test Loss: 0.001197 \tTest Accuracy: 0.267400\n",
      "Test Loss: 0.001199 \tTest Accuracy: 0.268467\n",
      "Test Loss: 0.001201 \tTest Accuracy: 0.269533\n",
      "Test Loss: 0.001201 \tTest Accuracy: 0.270600\n",
      "Test Loss: 0.001202 \tTest Accuracy: 0.271667\n",
      "Test Loss: 0.001206 \tTest Accuracy: 0.272733\n",
      "Test Loss: 0.001206 \tTest Accuracy: 0.273800\n",
      "Test Loss: 0.001206 \tTest Accuracy: 0.274867\n",
      "Test Loss: 0.001207 \tTest Accuracy: 0.275933\n",
      "Test Loss: 0.001222 \tTest Accuracy: 0.276983\n",
      "Test Loss: 0.001222 \tTest Accuracy: 0.278050\n",
      "Test Loss: 0.001222 \tTest Accuracy: 0.279117\n",
      "Test Loss: 0.001223 \tTest Accuracy: 0.280183\n",
      "Test Loss: 0.001223 \tTest Accuracy: 0.281250\n",
      "Test Loss: 0.001224 \tTest Accuracy: 0.282317\n",
      "Test Loss: 0.001224 \tTest Accuracy: 0.283383\n",
      "Test Loss: 0.001225 \tTest Accuracy: 0.284450\n",
      "Test Loss: 0.001225 \tTest Accuracy: 0.285517\n",
      "Test Loss: 0.001242 \tTest Accuracy: 0.286567\n",
      "Test Loss: 0.001242 \tTest Accuracy: 0.287633\n",
      "Test Loss: 0.001242 \tTest Accuracy: 0.288700\n",
      "Test Loss: 0.001254 \tTest Accuracy: 0.289750\n",
      "Test Loss: 0.001258 \tTest Accuracy: 0.290817\n",
      "Test Loss: 0.001259 \tTest Accuracy: 0.291883\n",
      "Test Loss: 0.001259 \tTest Accuracy: 0.292950\n",
      "Test Loss: 0.001259 \tTest Accuracy: 0.294017\n",
      "Test Loss: 0.001268 \tTest Accuracy: 0.295083\n",
      "Test Loss: 0.001268 \tTest Accuracy: 0.296150\n",
      "Test Loss: 0.001269 \tTest Accuracy: 0.297217\n",
      "Test Loss: 0.001283 \tTest Accuracy: 0.298267\n",
      "Test Loss: 0.001283 \tTest Accuracy: 0.299333\n",
      "Test Loss: 0.001285 \tTest Accuracy: 0.300400\n",
      "Test Loss: 0.001303 \tTest Accuracy: 0.301450\n",
      "Test Loss: 0.001303 \tTest Accuracy: 0.302517\n",
      "Test Loss: 0.001334 \tTest Accuracy: 0.303567\n",
      "Test Loss: 0.001334 \tTest Accuracy: 0.304633\n",
      "Test Loss: 0.001334 \tTest Accuracy: 0.305700\n",
      "Test Loss: 0.001335 \tTest Accuracy: 0.306767\n",
      "Test Loss: 0.001336 \tTest Accuracy: 0.307833\n",
      "Test Loss: 0.001337 \tTest Accuracy: 0.308900\n",
      "Test Loss: 0.001337 \tTest Accuracy: 0.309967\n",
      "Test Loss: 0.001338 \tTest Accuracy: 0.311033\n",
      "Test Loss: 0.001352 \tTest Accuracy: 0.312083\n",
      "Test Loss: 0.001352 \tTest Accuracy: 0.313150\n",
      "Test Loss: 0.001353 \tTest Accuracy: 0.314217\n",
      "Test Loss: 0.001355 \tTest Accuracy: 0.315283\n",
      "Test Loss: 0.001357 \tTest Accuracy: 0.316350\n",
      "Test Loss: 0.001360 \tTest Accuracy: 0.317417\n",
      "Test Loss: 0.001390 \tTest Accuracy: 0.318467\n",
      "Test Loss: 0.001390 \tTest Accuracy: 0.319533\n",
      "Test Loss: 0.001390 \tTest Accuracy: 0.320600\n",
      "Test Loss: 0.001392 \tTest Accuracy: 0.321667\n",
      "Test Loss: 0.001421 \tTest Accuracy: 0.322717\n",
      "Test Loss: 0.001427 \tTest Accuracy: 0.323783\n",
      "Test Loss: 0.001427 \tTest Accuracy: 0.324850\n",
      "Test Loss: 0.001427 \tTest Accuracy: 0.325917\n",
      "Test Loss: 0.001440 \tTest Accuracy: 0.326967\n",
      "Test Loss: 0.001441 \tTest Accuracy: 0.328033\n",
      "Test Loss: 0.001441 \tTest Accuracy: 0.329100\n",
      "Test Loss: 0.001452 \tTest Accuracy: 0.330167\n",
      "Test Loss: 0.001452 \tTest Accuracy: 0.331233\n",
      "Test Loss: 0.001452 \tTest Accuracy: 0.332300\n",
      "Test Loss: 0.001452 \tTest Accuracy: 0.333367\n",
      "Test Loss: 0.001452 \tTest Accuracy: 0.334433\n",
      "Test Loss: 0.001455 \tTest Accuracy: 0.335500\n",
      "Test Loss: 0.001455 \tTest Accuracy: 0.336567\n",
      "Test Loss: 0.001455 \tTest Accuracy: 0.337633\n",
      "Test Loss: 0.001466 \tTest Accuracy: 0.338700\n",
      "Test Loss: 0.001467 \tTest Accuracy: 0.339767\n",
      "Test Loss: 0.001468 \tTest Accuracy: 0.340833\n",
      "Test Loss: 0.001469 \tTest Accuracy: 0.341900\n",
      "Test Loss: 0.001469 \tTest Accuracy: 0.342967\n",
      "Test Loss: 0.001472 \tTest Accuracy: 0.344033\n",
      "Test Loss: 0.001478 \tTest Accuracy: 0.345100\n",
      "Test Loss: 0.001478 \tTest Accuracy: 0.346167\n",
      "Test Loss: 0.001479 \tTest Accuracy: 0.347233\n",
      "Test Loss: 0.001479 \tTest Accuracy: 0.348300\n",
      "Test Loss: 0.001480 \tTest Accuracy: 0.349367\n",
      "Test Loss: 0.001482 \tTest Accuracy: 0.350433\n",
      "Test Loss: 0.001522 \tTest Accuracy: 0.351467\n",
      "Test Loss: 0.001522 \tTest Accuracy: 0.352533\n",
      "Test Loss: 0.001522 \tTest Accuracy: 0.353600\n",
      "Test Loss: 0.001523 \tTest Accuracy: 0.354667\n",
      "Test Loss: 0.001523 \tTest Accuracy: 0.355733\n",
      "Test Loss: 0.001524 \tTest Accuracy: 0.356800\n",
      "Test Loss: 0.001524 \tTest Accuracy: 0.357867\n",
      "Test Loss: 0.001524 \tTest Accuracy: 0.358933\n",
      "Test Loss: 0.001531 \tTest Accuracy: 0.360000\n",
      "Test Loss: 0.001531 \tTest Accuracy: 0.361067\n",
      "Test Loss: 0.001531 \tTest Accuracy: 0.362133\n",
      "Test Loss: 0.001531 \tTest Accuracy: 0.363200\n",
      "Test Loss: 0.001532 \tTest Accuracy: 0.364267\n",
      "Test Loss: 0.001535 \tTest Accuracy: 0.365333\n",
      "Test Loss: 0.001535 \tTest Accuracy: 0.366400\n",
      "Test Loss: 0.001543 \tTest Accuracy: 0.367467\n",
      "Test Loss: 0.001543 \tTest Accuracy: 0.368533\n",
      "Test Loss: 0.001547 \tTest Accuracy: 0.369600\n",
      "Test Loss: 0.001550 \tTest Accuracy: 0.370667\n",
      "Test Loss: 0.001550 \tTest Accuracy: 0.371733\n",
      "Test Loss: 0.001551 \tTest Accuracy: 0.372800\n",
      "Test Loss: 0.001553 \tTest Accuracy: 0.373867\n",
      "Test Loss: 0.001555 \tTest Accuracy: 0.374933\n",
      "Test Loss: 0.001556 \tTest Accuracy: 0.376000\n",
      "Test Loss: 0.001556 \tTest Accuracy: 0.377067\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.378117\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.379183\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.380250\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.381317\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.382383\n",
      "Test Loss: 0.001574 \tTest Accuracy: 0.383450\n",
      "Test Loss: 0.001575 \tTest Accuracy: 0.384517\n",
      "Test Loss: 0.001579 \tTest Accuracy: 0.385583\n",
      "Test Loss: 0.001580 \tTest Accuracy: 0.386650\n",
      "Test Loss: 0.001580 \tTest Accuracy: 0.387717\n",
      "Test Loss: 0.001587 \tTest Accuracy: 0.388783\n",
      "Test Loss: 0.001614 \tTest Accuracy: 0.389833\n",
      "Test Loss: 0.001615 \tTest Accuracy: 0.390900\n",
      "Test Loss: 0.001664 \tTest Accuracy: 0.391950\n",
      "Test Loss: 0.001666 \tTest Accuracy: 0.393017\n",
      "Test Loss: 0.001666 \tTest Accuracy: 0.394083\n",
      "Test Loss: 0.001666 \tTest Accuracy: 0.395150\n",
      "Test Loss: 0.001673 \tTest Accuracy: 0.396217\n",
      "Test Loss: 0.001675 \tTest Accuracy: 0.397283\n",
      "Test Loss: 0.001675 \tTest Accuracy: 0.398350\n",
      "Test Loss: 0.001675 \tTest Accuracy: 0.399417\n",
      "Test Loss: 0.001675 \tTest Accuracy: 0.400483\n",
      "Test Loss: 0.001676 \tTest Accuracy: 0.401550\n",
      "Test Loss: 0.001677 \tTest Accuracy: 0.402617\n",
      "Test Loss: 0.001677 \tTest Accuracy: 0.403683\n",
      "Test Loss: 0.001677 \tTest Accuracy: 0.404750\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.405817\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.406883\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.407950\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.409017\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.410083\n",
      "Test Loss: 0.001678 \tTest Accuracy: 0.411150\n",
      "Test Loss: 0.001679 \tTest Accuracy: 0.412217\n",
      "Test Loss: 0.001679 \tTest Accuracy: 0.413283\n",
      "Test Loss: 0.001680 \tTest Accuracy: 0.414350\n",
      "Test Loss: 0.001680 \tTest Accuracy: 0.415417\n",
      "Test Loss: 0.001726 \tTest Accuracy: 0.416467\n",
      "Test Loss: 0.001726 \tTest Accuracy: 0.417533\n",
      "Test Loss: 0.001727 \tTest Accuracy: 0.418600\n",
      "Test Loss: 0.001728 \tTest Accuracy: 0.419667\n",
      "Test Loss: 0.001728 \tTest Accuracy: 0.420733\n",
      "Test Loss: 0.001734 \tTest Accuracy: 0.421800\n",
      "Test Loss: 0.001735 \tTest Accuracy: 0.422867\n",
      "Test Loss: 0.001737 \tTest Accuracy: 0.423933\n",
      "Test Loss: 0.001758 \tTest Accuracy: 0.424983\n",
      "Test Loss: 0.001759 \tTest Accuracy: 0.426050\n",
      "Test Loss: 0.001760 \tTest Accuracy: 0.427117\n",
      "Test Loss: 0.001762 \tTest Accuracy: 0.428183\n",
      "Test Loss: 0.001764 \tTest Accuracy: 0.429250\n",
      "Test Loss: 0.001786 \tTest Accuracy: 0.430300\n",
      "Test Loss: 0.001787 \tTest Accuracy: 0.431367\n",
      "Test Loss: 0.001787 \tTest Accuracy: 0.432433\n",
      "Test Loss: 0.001787 \tTest Accuracy: 0.433500\n",
      "Test Loss: 0.001787 \tTest Accuracy: 0.434567\n",
      "Test Loss: 0.001798 \tTest Accuracy: 0.435633\n",
      "Test Loss: 0.001798 \tTest Accuracy: 0.436700\n",
      "Test Loss: 0.001798 \tTest Accuracy: 0.437767\n",
      "Test Loss: 0.001798 \tTest Accuracy: 0.438833\n",
      "Test Loss: 0.001799 \tTest Accuracy: 0.439900\n",
      "Test Loss: 0.001799 \tTest Accuracy: 0.440967\n",
      "Test Loss: 0.001799 \tTest Accuracy: 0.442033\n",
      "Test Loss: 0.001806 \tTest Accuracy: 0.443100\n",
      "Test Loss: 0.001810 \tTest Accuracy: 0.444167\n",
      "Test Loss: 0.001812 \tTest Accuracy: 0.445233\n",
      "Test Loss: 0.001814 \tTest Accuracy: 0.446300\n",
      "Test Loss: 0.001815 \tTest Accuracy: 0.447367\n",
      "Test Loss: 0.001819 \tTest Accuracy: 0.448433\n",
      "Test Loss: 0.001819 \tTest Accuracy: 0.449500\n",
      "Test Loss: 0.001821 \tTest Accuracy: 0.450567\n",
      "Test Loss: 0.001821 \tTest Accuracy: 0.451633\n",
      "Test Loss: 0.001821 \tTest Accuracy: 0.452700\n",
      "Test Loss: 0.001822 \tTest Accuracy: 0.453767\n",
      "Test Loss: 0.001844 \tTest Accuracy: 0.454817\n",
      "Test Loss: 0.001845 \tTest Accuracy: 0.455883\n",
      "Test Loss: 0.001845 \tTest Accuracy: 0.456950\n",
      "Test Loss: 0.001849 \tTest Accuracy: 0.458017\n",
      "Test Loss: 0.001853 \tTest Accuracy: 0.459083\n",
      "Test Loss: 0.001854 \tTest Accuracy: 0.460150\n",
      "Test Loss: 0.001855 \tTest Accuracy: 0.461217\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.462283\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.463350\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.464417\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.465483\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.466550\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.467617\n",
      "Test Loss: 0.001856 \tTest Accuracy: 0.468683\n",
      "Test Loss: 0.001866 \tTest Accuracy: 0.469750\n",
      "Test Loss: 0.001866 \tTest Accuracy: 0.470817\n",
      "Test Loss: 0.001867 \tTest Accuracy: 0.471883\n",
      "Test Loss: 0.001867 \tTest Accuracy: 0.472950\n",
      "Test Loss: 0.001868 \tTest Accuracy: 0.474017\n",
      "Test Loss: 0.001868 \tTest Accuracy: 0.475083\n",
      "Test Loss: 0.001868 \tTest Accuracy: 0.476150\n",
      "Test Loss: 0.001869 \tTest Accuracy: 0.477217\n",
      "Test Loss: 0.001871 \tTest Accuracy: 0.478283\n",
      "Test Loss: 0.001872 \tTest Accuracy: 0.479350\n",
      "Test Loss: 0.001873 \tTest Accuracy: 0.480417\n",
      "Test Loss: 0.001879 \tTest Accuracy: 0.481483\n",
      "Test Loss: 0.001894 \tTest Accuracy: 0.482550\n",
      "Test Loss: 0.001894 \tTest Accuracy: 0.483617\n",
      "Test Loss: 0.001901 \tTest Accuracy: 0.484683\n",
      "Test Loss: 0.001902 \tTest Accuracy: 0.485750\n",
      "Test Loss: 0.001911 \tTest Accuracy: 0.486817\n",
      "Test Loss: 0.001912 \tTest Accuracy: 0.487883\n",
      "Test Loss: 0.001913 \tTest Accuracy: 0.488950\n",
      "Test Loss: 0.001913 \tTest Accuracy: 0.490017\n",
      "Test Loss: 0.001915 \tTest Accuracy: 0.491083\n",
      "Test Loss: 0.001946 \tTest Accuracy: 0.492133\n",
      "Test Loss: 0.001946 \tTest Accuracy: 0.493200\n",
      "Test Loss: 0.001949 \tTest Accuracy: 0.494267\n",
      "Test Loss: 0.001949 \tTest Accuracy: 0.495333\n",
      "Test Loss: 0.001949 \tTest Accuracy: 0.496400\n",
      "Test Loss: 0.001949 \tTest Accuracy: 0.497467\n",
      "Test Loss: 0.001952 \tTest Accuracy: 0.498533\n",
      "Test Loss: 0.001953 \tTest Accuracy: 0.499600\n",
      "Test Loss: 0.001953 \tTest Accuracy: 0.500667\n",
      "Test Loss: 0.001953 \tTest Accuracy: 0.501733\n",
      "Test Loss: 0.001955 \tTest Accuracy: 0.502800\n",
      "Test Loss: 0.001956 \tTest Accuracy: 0.503867\n",
      "Test Loss: 0.001962 \tTest Accuracy: 0.504933\n",
      "Test Loss: 0.001963 \tTest Accuracy: 0.506000\n",
      "Test Loss: 0.001964 \tTest Accuracy: 0.507067\n",
      "Test Loss: 0.001964 \tTest Accuracy: 0.508133\n",
      "Test Loss: 0.001964 \tTest Accuracy: 0.509200\n",
      "Test Loss: 0.001992 \tTest Accuracy: 0.510250\n",
      "Test Loss: 0.001992 \tTest Accuracy: 0.511317\n",
      "Test Loss: 0.001993 \tTest Accuracy: 0.512383\n",
      "Test Loss: 0.001993 \tTest Accuracy: 0.513450\n",
      "Test Loss: 0.002008 \tTest Accuracy: 0.514517\n",
      "Test Loss: 0.002010 \tTest Accuracy: 0.515583\n",
      "Test Loss: 0.002011 \tTest Accuracy: 0.516650\n",
      "Test Loss: 0.002097 \tTest Accuracy: 0.517700\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.518767\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.519833\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.520900\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.521967\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.523033\n",
      "Test Loss: 0.002098 \tTest Accuracy: 0.524100\n",
      "Test Loss: 0.002099 \tTest Accuracy: 0.525167\n",
      "Test Loss: 0.002100 \tTest Accuracy: 0.526233\n",
      "Test Loss: 0.002100 \tTest Accuracy: 0.527300\n",
      "Test Loss: 0.002106 \tTest Accuracy: 0.528367\n",
      "Test Loss: 0.002106 \tTest Accuracy: 0.529433\n",
      "Test Loss: 0.002112 \tTest Accuracy: 0.530500\n",
      "Test Loss: 0.002118 \tTest Accuracy: 0.531567\n",
      "Test Loss: 0.002120 \tTest Accuracy: 0.532633\n",
      "Test Loss: 0.002144 \tTest Accuracy: 0.533683\n",
      "Test Loss: 0.002146 \tTest Accuracy: 0.534750\n",
      "Test Loss: 0.002152 \tTest Accuracy: 0.535817\n",
      "Test Loss: 0.002155 \tTest Accuracy: 0.536883\n",
      "Test Loss: 0.002156 \tTest Accuracy: 0.537950\n",
      "Test Loss: 0.002157 \tTest Accuracy: 0.539017\n",
      "Test Loss: 0.002157 \tTest Accuracy: 0.540083\n",
      "Test Loss: 0.002210 \tTest Accuracy: 0.541133\n",
      "Test Loss: 0.002212 \tTest Accuracy: 0.542200\n",
      "Test Loss: 0.002221 \tTest Accuracy: 0.543267\n",
      "Test Loss: 0.002221 \tTest Accuracy: 0.544333\n",
      "Test Loss: 0.002221 \tTest Accuracy: 0.545400\n",
      "Test Loss: 0.002229 \tTest Accuracy: 0.546467\n",
      "Test Loss: 0.002229 \tTest Accuracy: 0.547533\n",
      "Test Loss: 0.002234 \tTest Accuracy: 0.548600\n",
      "Test Loss: 0.002252 \tTest Accuracy: 0.549650\n",
      "Test Loss: 0.002252 \tTest Accuracy: 0.550717\n",
      "Test Loss: 0.002255 \tTest Accuracy: 0.551783\n",
      "Test Loss: 0.002329 \tTest Accuracy: 0.552833\n",
      "Test Loss: 0.002334 \tTest Accuracy: 0.553900\n",
      "Test Loss: 0.002334 \tTest Accuracy: 0.554967\n",
      "Test Loss: 0.002340 \tTest Accuracy: 0.556033\n",
      "Test Loss: 0.002340 \tTest Accuracy: 0.557100\n",
      "Test Loss: 0.002341 \tTest Accuracy: 0.558167\n",
      "Test Loss: 0.002346 \tTest Accuracy: 0.559233\n",
      "Test Loss: 0.002346 \tTest Accuracy: 0.560300\n",
      "Test Loss: 0.002346 \tTest Accuracy: 0.561367\n",
      "Test Loss: 0.002376 \tTest Accuracy: 0.562417\n",
      "Test Loss: 0.002376 \tTest Accuracy: 0.563483\n",
      "Test Loss: 0.002380 \tTest Accuracy: 0.564550\n",
      "Test Loss: 0.002382 \tTest Accuracy: 0.565617\n",
      "Test Loss: 0.002382 \tTest Accuracy: 0.566683\n",
      "Test Loss: 0.002385 \tTest Accuracy: 0.567750\n",
      "Test Loss: 0.002385 \tTest Accuracy: 0.568817\n",
      "Test Loss: 0.002386 \tTest Accuracy: 0.569883\n",
      "Test Loss: 0.002392 \tTest Accuracy: 0.570950\n",
      "Test Loss: 0.002400 \tTest Accuracy: 0.572017\n",
      "Test Loss: 0.002405 \tTest Accuracy: 0.573083\n",
      "Test Loss: 0.002406 \tTest Accuracy: 0.574150\n",
      "Test Loss: 0.002406 \tTest Accuracy: 0.575217\n",
      "Test Loss: 0.002410 \tTest Accuracy: 0.576283\n",
      "Test Loss: 0.002410 \tTest Accuracy: 0.577350\n",
      "Test Loss: 0.002412 \tTest Accuracy: 0.578417\n",
      "Test Loss: 0.002412 \tTest Accuracy: 0.579483\n",
      "Test Loss: 0.002412 \tTest Accuracy: 0.580550\n",
      "Test Loss: 0.002412 \tTest Accuracy: 0.581617\n",
      "Test Loss: 0.002413 \tTest Accuracy: 0.582683\n",
      "Test Loss: 0.002414 \tTest Accuracy: 0.583750\n",
      "Test Loss: 0.002414 \tTest Accuracy: 0.584817\n",
      "Test Loss: 0.002414 \tTest Accuracy: 0.585883\n",
      "Test Loss: 0.002414 \tTest Accuracy: 0.586950\n",
      "Test Loss: 0.002421 \tTest Accuracy: 0.588017\n",
      "Test Loss: 0.002421 \tTest Accuracy: 0.589083\n",
      "Test Loss: 0.002423 \tTest Accuracy: 0.590150\n",
      "Test Loss: 0.002435 \tTest Accuracy: 0.591200\n",
      "Test Loss: 0.002436 \tTest Accuracy: 0.592267\n",
      "Test Loss: 0.002436 \tTest Accuracy: 0.593333\n",
      "Test Loss: 0.002436 \tTest Accuracy: 0.594400\n",
      "Test Loss: 0.002436 \tTest Accuracy: 0.595467\n",
      "Test Loss: 0.002439 \tTest Accuracy: 0.596533\n",
      "Test Loss: 0.002439 \tTest Accuracy: 0.597600\n",
      "Test Loss: 0.002440 \tTest Accuracy: 0.598667\n",
      "Test Loss: 0.002440 \tTest Accuracy: 0.599733\n",
      "Test Loss: 0.002440 \tTest Accuracy: 0.600800\n",
      "Test Loss: 0.002443 \tTest Accuracy: 0.601867\n",
      "Test Loss: 0.002443 \tTest Accuracy: 0.602933\n",
      "Test Loss: 0.002444 \tTest Accuracy: 0.604000\n",
      "Test Loss: 0.002555 \tTest Accuracy: 0.605033\n",
      "Test Loss: 0.002556 \tTest Accuracy: 0.606100\n",
      "Test Loss: 0.002557 \tTest Accuracy: 0.607167\n",
      "Test Loss: 0.002558 \tTest Accuracy: 0.608233\n",
      "Test Loss: 0.002558 \tTest Accuracy: 0.609300\n",
      "Test Loss: 0.002558 \tTest Accuracy: 0.610367\n",
      "Test Loss: 0.002622 \tTest Accuracy: 0.611400\n",
      "Test Loss: 0.002623 \tTest Accuracy: 0.612467\n",
      "Test Loss: 0.002625 \tTest Accuracy: 0.613533\n",
      "Test Loss: 0.002625 \tTest Accuracy: 0.614600\n",
      "Test Loss: 0.002625 \tTest Accuracy: 0.615667\n",
      "Test Loss: 0.002625 \tTest Accuracy: 0.616733\n",
      "Test Loss: 0.002625 \tTest Accuracy: 0.617800\n",
      "Test Loss: 0.002631 \tTest Accuracy: 0.618867\n",
      "Test Loss: 0.002631 \tTest Accuracy: 0.619933\n",
      "Test Loss: 0.002631 \tTest Accuracy: 0.621000\n",
      "Test Loss: 0.002631 \tTest Accuracy: 0.622067\n",
      "Test Loss: 0.002632 \tTest Accuracy: 0.623133\n",
      "Test Loss: 0.002646 \tTest Accuracy: 0.624183\n",
      "Test Loss: 0.002647 \tTest Accuracy: 0.625250\n",
      "Test Loss: 0.002649 \tTest Accuracy: 0.626317\n",
      "Test Loss: 0.002651 \tTest Accuracy: 0.627383\n",
      "Test Loss: 0.002651 \tTest Accuracy: 0.628450\n",
      "Test Loss: 0.002651 \tTest Accuracy: 0.629517\n",
      "Test Loss: 0.002652 \tTest Accuracy: 0.630583\n",
      "Test Loss: 0.002652 \tTest Accuracy: 0.631650\n",
      "Test Loss: 0.002660 \tTest Accuracy: 0.632717\n",
      "Test Loss: 0.002702 \tTest Accuracy: 0.633750\n",
      "Test Loss: 0.002703 \tTest Accuracy: 0.634817\n",
      "Test Loss: 0.002703 \tTest Accuracy: 0.635883\n",
      "Test Loss: 0.002703 \tTest Accuracy: 0.636950\n",
      "Test Loss: 0.002706 \tTest Accuracy: 0.638017\n",
      "Test Loss: 0.002706 \tTest Accuracy: 0.639083\n",
      "Test Loss: 0.002706 \tTest Accuracy: 0.640150\n",
      "Test Loss: 0.002707 \tTest Accuracy: 0.641217\n",
      "Test Loss: 0.002707 \tTest Accuracy: 0.642283\n",
      "Test Loss: 0.002707 \tTest Accuracy: 0.643350\n",
      "Test Loss: 0.002707 \tTest Accuracy: 0.644417\n",
      "Test Loss: 0.002707 \tTest Accuracy: 0.645483\n",
      "Test Loss: 0.002709 \tTest Accuracy: 0.646550\n",
      "Test Loss: 0.002710 \tTest Accuracy: 0.647617\n",
      "Test Loss: 0.002711 \tTest Accuracy: 0.648683\n",
      "Test Loss: 0.002711 \tTest Accuracy: 0.649750\n",
      "Test Loss: 0.002711 \tTest Accuracy: 0.650817\n",
      "Test Loss: 0.002712 \tTest Accuracy: 0.651883\n",
      "Test Loss: 0.002713 \tTest Accuracy: 0.652950\n",
      "Test Loss: 0.002714 \tTest Accuracy: 0.654017\n",
      "Test Loss: 0.002725 \tTest Accuracy: 0.655083\n",
      "Test Loss: 0.002725 \tTest Accuracy: 0.656150\n",
      "Test Loss: 0.002726 \tTest Accuracy: 0.657217\n",
      "Test Loss: 0.002726 \tTest Accuracy: 0.658283\n",
      "Test Loss: 0.002726 \tTest Accuracy: 0.659350\n",
      "Test Loss: 0.002726 \tTest Accuracy: 0.660417\n",
      "Test Loss: 0.002728 \tTest Accuracy: 0.661483\n",
      "Test Loss: 0.002730 \tTest Accuracy: 0.662550\n",
      "Test Loss: 0.002730 \tTest Accuracy: 0.663617\n",
      "Test Loss: 0.002730 \tTest Accuracy: 0.664683\n",
      "Test Loss: 0.002739 \tTest Accuracy: 0.665750\n",
      "Test Loss: 0.002741 \tTest Accuracy: 0.666817\n",
      "Test Loss: 0.002742 \tTest Accuracy: 0.667883\n",
      "Test Loss: 0.002742 \tTest Accuracy: 0.668950\n",
      "Test Loss: 0.002742 \tTest Accuracy: 0.670017\n",
      "Test Loss: 0.002742 \tTest Accuracy: 0.671083\n",
      "Test Loss: 0.002743 \tTest Accuracy: 0.672150\n",
      "Test Loss: 0.002771 \tTest Accuracy: 0.673200\n",
      "Test Loss: 0.002778 \tTest Accuracy: 0.674267\n",
      "Test Loss: 0.002778 \tTest Accuracy: 0.675333\n",
      "Test Loss: 0.002779 \tTest Accuracy: 0.676400\n",
      "Test Loss: 0.002786 \tTest Accuracy: 0.677467\n",
      "Test Loss: 0.002786 \tTest Accuracy: 0.678533\n",
      "Test Loss: 0.002803 \tTest Accuracy: 0.679583\n",
      "Test Loss: 0.002804 \tTest Accuracy: 0.680650\n",
      "Test Loss: 0.002804 \tTest Accuracy: 0.681717\n",
      "Test Loss: 0.002804 \tTest Accuracy: 0.682783\n",
      "Test Loss: 0.002807 \tTest Accuracy: 0.683850\n",
      "Test Loss: 0.002808 \tTest Accuracy: 0.684917\n",
      "Test Loss: 0.002810 \tTest Accuracy: 0.685983\n",
      "Test Loss: 0.002810 \tTest Accuracy: 0.687050\n",
      "Test Loss: 0.002810 \tTest Accuracy: 0.688117\n",
      "Test Loss: 0.002811 \tTest Accuracy: 0.689183\n",
      "Test Loss: 0.002811 \tTest Accuracy: 0.690250\n",
      "Test Loss: 0.002839 \tTest Accuracy: 0.691300\n",
      "Test Loss: 0.002839 \tTest Accuracy: 0.692367\n",
      "Test Loss: 0.002839 \tTest Accuracy: 0.693433\n",
      "Test Loss: 0.002840 \tTest Accuracy: 0.694500\n",
      "Test Loss: 0.002841 \tTest Accuracy: 0.695567\n",
      "Test Loss: 0.002843 \tTest Accuracy: 0.696633\n",
      "Test Loss: 0.002847 \tTest Accuracy: 0.697700\n",
      "Test Loss: 0.002847 \tTest Accuracy: 0.698767\n",
      "Test Loss: 0.002854 \tTest Accuracy: 0.699833\n",
      "Test Loss: 0.002857 \tTest Accuracy: 0.700900\n",
      "Test Loss: 0.002858 \tTest Accuracy: 0.701967\n",
      "Test Loss: 0.002860 \tTest Accuracy: 0.703033\n",
      "Test Loss: 0.002860 \tTest Accuracy: 0.704100\n",
      "Test Loss: 0.002860 \tTest Accuracy: 0.705167\n",
      "Test Loss: 0.002861 \tTest Accuracy: 0.706233\n",
      "Test Loss: 0.002863 \tTest Accuracy: 0.707300\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.708367\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.709433\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.710500\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.711567\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.712633\n",
      "Test Loss: 0.002866 \tTest Accuracy: 0.713700\n",
      "Test Loss: 0.002867 \tTest Accuracy: 0.714767\n",
      "Test Loss: 0.002892 \tTest Accuracy: 0.715817\n",
      "Test Loss: 0.002893 \tTest Accuracy: 0.716883\n",
      "Test Loss: 0.002893 \tTest Accuracy: 0.717950\n",
      "Test Loss: 0.002893 \tTest Accuracy: 0.719017\n",
      "Test Loss: 0.002893 \tTest Accuracy: 0.720083\n",
      "Test Loss: 0.002895 \tTest Accuracy: 0.721150\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.722217\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.723283\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.724350\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.725417\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.726483\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.727550\n",
      "Test Loss: 0.002904 \tTest Accuracy: 0.728617\n",
      "Test Loss: 0.002905 \tTest Accuracy: 0.729683\n",
      "Test Loss: 0.002909 \tTest Accuracy: 0.730750\n",
      "Test Loss: 0.002910 \tTest Accuracy: 0.731817\n",
      "Test Loss: 0.002913 \tTest Accuracy: 0.732883\n",
      "Test Loss: 0.002916 \tTest Accuracy: 0.733950\n",
      "Test Loss: 0.002917 \tTest Accuracy: 0.735017\n",
      "Test Loss: 0.002919 \tTest Accuracy: 0.736083\n",
      "Test Loss: 0.002919 \tTest Accuracy: 0.737150\n",
      "Test Loss: 0.002950 \tTest Accuracy: 0.738200\n",
      "Test Loss: 0.002962 \tTest Accuracy: 0.739267\n",
      "Test Loss: 0.002963 \tTest Accuracy: 0.740333\n",
      "Test Loss: 0.002963 \tTest Accuracy: 0.741400\n",
      "Test Loss: 0.002968 \tTest Accuracy: 0.742467\n",
      "Test Loss: 0.002970 \tTest Accuracy: 0.743533\n",
      "Test Loss: 0.002970 \tTest Accuracy: 0.744600\n",
      "Test Loss: 0.002989 \tTest Accuracy: 0.745650\n",
      "Test Loss: 0.003007 \tTest Accuracy: 0.746700\n",
      "Test Loss: 0.003007 \tTest Accuracy: 0.747767\n",
      "Test Loss: 0.003008 \tTest Accuracy: 0.748833\n",
      "Test Loss: 0.003009 \tTest Accuracy: 0.749900\n",
      "Test Loss: 0.003009 \tTest Accuracy: 0.750967\n",
      "Test Loss: 0.003010 \tTest Accuracy: 0.752033\n",
      "Test Loss: 0.003010 \tTest Accuracy: 0.753100\n",
      "Test Loss: 0.003010 \tTest Accuracy: 0.754167\n",
      "Test Loss: 0.003011 \tTest Accuracy: 0.755233\n",
      "Test Loss: 0.003013 \tTest Accuracy: 0.756300\n",
      "Test Loss: 0.003013 \tTest Accuracy: 0.757367\n",
      "Test Loss: 0.003013 \tTest Accuracy: 0.758433\n",
      "Test Loss: 0.003021 \tTest Accuracy: 0.759500\n",
      "Test Loss: 0.003021 \tTest Accuracy: 0.760567\n",
      "Test Loss: 0.003022 \tTest Accuracy: 0.761633\n",
      "Test Loss: 0.003022 \tTest Accuracy: 0.762700\n",
      "Test Loss: 0.003024 \tTest Accuracy: 0.763767\n",
      "Test Loss: 0.003024 \tTest Accuracy: 0.764833\n",
      "Test Loss: 0.003024 \tTest Accuracy: 0.765900\n",
      "Test Loss: 0.003026 \tTest Accuracy: 0.766967\n",
      "Test Loss: 0.003027 \tTest Accuracy: 0.768033\n",
      "Test Loss: 0.003027 \tTest Accuracy: 0.769100\n",
      "Test Loss: 0.003028 \tTest Accuracy: 0.770167\n",
      "Test Loss: 0.003034 \tTest Accuracy: 0.771233\n",
      "Test Loss: 0.003035 \tTest Accuracy: 0.772300\n",
      "Test Loss: 0.003036 \tTest Accuracy: 0.773367\n",
      "Test Loss: 0.003059 \tTest Accuracy: 0.774417\n",
      "Test Loss: 0.003059 \tTest Accuracy: 0.775483\n",
      "Test Loss: 0.003061 \tTest Accuracy: 0.776550\n",
      "Test Loss: 0.003061 \tTest Accuracy: 0.777617\n",
      "Test Loss: 0.003061 \tTest Accuracy: 0.778683\n",
      "Test Loss: 0.003061 \tTest Accuracy: 0.779750\n",
      "Test Loss: 0.003067 \tTest Accuracy: 0.780817\n",
      "Test Loss: 0.003068 \tTest Accuracy: 0.781883\n",
      "Test Loss: 0.003068 \tTest Accuracy: 0.782950\n",
      "Test Loss: 0.003070 \tTest Accuracy: 0.784017\n",
      "Test Loss: 0.003071 \tTest Accuracy: 0.785083\n",
      "Test Loss: 0.003086 \tTest Accuracy: 0.786133\n",
      "Test Loss: 0.003086 \tTest Accuracy: 0.787200\n",
      "Test Loss: 0.003090 \tTest Accuracy: 0.788267\n",
      "Test Loss: 0.003091 \tTest Accuracy: 0.789333\n",
      "Test Loss: 0.003091 \tTest Accuracy: 0.790400\n",
      "Test Loss: 0.003091 \tTest Accuracy: 0.791467\n",
      "Test Loss: 0.003091 \tTest Accuracy: 0.792533\n",
      "Test Loss: 0.003094 \tTest Accuracy: 0.793600\n",
      "Test Loss: 0.003095 \tTest Accuracy: 0.794667\n",
      "Test Loss: 0.003095 \tTest Accuracy: 0.795733\n",
      "Test Loss: 0.003097 \tTest Accuracy: 0.796800\n",
      "Test Loss: 0.003097 \tTest Accuracy: 0.797867\n",
      "Test Loss: 0.003097 \tTest Accuracy: 0.798933\n",
      "Test Loss: 0.003097 \tTest Accuracy: 0.800000\n",
      "Test Loss: 0.003099 \tTest Accuracy: 0.801067\n",
      "Test Loss: 0.003101 \tTest Accuracy: 0.802133\n",
      "Test Loss: 0.003101 \tTest Accuracy: 0.803200\n",
      "Test Loss: 0.003102 \tTest Accuracy: 0.804267\n",
      "Test Loss: 0.003103 \tTest Accuracy: 0.805333\n",
      "Test Loss: 0.003104 \tTest Accuracy: 0.806400\n",
      "Test Loss: 0.003104 \tTest Accuracy: 0.807467\n",
      "Test Loss: 0.003104 \tTest Accuracy: 0.808533\n",
      "Test Loss: 0.003105 \tTest Accuracy: 0.809600\n",
      "Test Loss: 0.003105 \tTest Accuracy: 0.810667\n",
      "Test Loss: 0.003107 \tTest Accuracy: 0.811733\n",
      "Test Loss: 0.003161 \tTest Accuracy: 0.812783\n",
      "Test Loss: 0.003162 \tTest Accuracy: 0.813850\n",
      "Test Loss: 0.003175 \tTest Accuracy: 0.814900\n",
      "Test Loss: 0.003176 \tTest Accuracy: 0.815967\n",
      "Test Loss: 0.003176 \tTest Accuracy: 0.817033\n",
      "Test Loss: 0.003176 \tTest Accuracy: 0.818100\n",
      "Test Loss: 0.003177 \tTest Accuracy: 0.819167\n",
      "Test Loss: 0.003185 \tTest Accuracy: 0.820233\n",
      "Test Loss: 0.003186 \tTest Accuracy: 0.821300\n",
      "Test Loss: 0.003186 \tTest Accuracy: 0.822367\n",
      "Test Loss: 0.003262 \tTest Accuracy: 0.823417\n",
      "Test Loss: 0.003263 \tTest Accuracy: 0.824483\n",
      "Test Loss: 0.003271 \tTest Accuracy: 0.825550\n",
      "Test Loss: 0.003271 \tTest Accuracy: 0.826617\n",
      "Test Loss: 0.003271 \tTest Accuracy: 0.827683\n",
      "Test Loss: 0.003271 \tTest Accuracy: 0.828750\n",
      "Test Loss: 0.003274 \tTest Accuracy: 0.829817\n",
      "Test Loss: 0.003292 \tTest Accuracy: 0.830867\n",
      "Test Loss: 0.003297 \tTest Accuracy: 0.831933\n",
      "Test Loss: 0.003298 \tTest Accuracy: 0.833000\n",
      "Test Loss: 0.003299 \tTest Accuracy: 0.834067\n",
      "Test Loss: 0.003301 \tTest Accuracy: 0.835133\n",
      "Test Loss: 0.003301 \tTest Accuracy: 0.836200\n",
      "Test Loss: 0.003301 \tTest Accuracy: 0.837267\n",
      "Test Loss: 0.003302 \tTest Accuracy: 0.838333\n",
      "Test Loss: 0.003303 \tTest Accuracy: 0.839400\n",
      "Test Loss: 0.003303 \tTest Accuracy: 0.840467\n",
      "Test Loss: 0.003311 \tTest Accuracy: 0.841533\n",
      "Test Loss: 0.003311 \tTest Accuracy: 0.842600\n",
      "Test Loss: 0.003312 \tTest Accuracy: 0.843667\n",
      "Test Loss: 0.003316 \tTest Accuracy: 0.844733\n",
      "Test Loss: 0.003318 \tTest Accuracy: 0.845800\n",
      "Test Loss: 0.003323 \tTest Accuracy: 0.846867\n",
      "Test Loss: 0.003323 \tTest Accuracy: 0.847933\n",
      "Test Loss: 0.003364 \tTest Accuracy: 0.848983\n",
      "Test Loss: 0.003365 \tTest Accuracy: 0.850050\n",
      "Test Loss: 0.003366 \tTest Accuracy: 0.851117\n",
      "Test Loss: 0.003374 \tTest Accuracy: 0.852183\n",
      "Test Loss: 0.003376 \tTest Accuracy: 0.853250\n",
      "Test Loss: 0.003382 \tTest Accuracy: 0.854317\n",
      "Test Loss: 0.003382 \tTest Accuracy: 0.855383\n",
      "Test Loss: 0.003382 \tTest Accuracy: 0.856450\n",
      "Test Loss: 0.003387 \tTest Accuracy: 0.857517\n",
      "Test Loss: 0.003388 \tTest Accuracy: 0.858583\n",
      "Test Loss: 0.003396 \tTest Accuracy: 0.859650\n",
      "Test Loss: 0.003396 \tTest Accuracy: 0.860717\n",
      "Test Loss: 0.003397 \tTest Accuracy: 0.861783\n",
      "Test Loss: 0.003397 \tTest Accuracy: 0.862850\n",
      "Test Loss: 0.003402 \tTest Accuracy: 0.863917\n",
      "Test Loss: 0.003404 \tTest Accuracy: 0.864983\n",
      "Test Loss: 0.003404 \tTest Accuracy: 0.866050\n",
      "Test Loss: 0.003404 \tTest Accuracy: 0.867117\n",
      "Test Loss: 0.003404 \tTest Accuracy: 0.868183\n",
      "Test Loss: 0.003407 \tTest Accuracy: 0.869250\n",
      "Test Loss: 0.003408 \tTest Accuracy: 0.870317\n",
      "Test Loss: 0.003409 \tTest Accuracy: 0.871383\n",
      "Test Loss: 0.003437 \tTest Accuracy: 0.872433\n",
      "Test Loss: 0.003437 \tTest Accuracy: 0.873500\n",
      "Test Loss: 0.003438 \tTest Accuracy: 0.874567\n",
      "Test Loss: 0.003438 \tTest Accuracy: 0.875633\n",
      "Test Loss: 0.003438 \tTest Accuracy: 0.876700\n",
      "Test Loss: 0.003439 \tTest Accuracy: 0.877767\n",
      "Test Loss: 0.003450 \tTest Accuracy: 0.878833\n",
      "Test Loss: 0.003450 \tTest Accuracy: 0.879900\n",
      "Test Loss: 0.003450 \tTest Accuracy: 0.880967\n",
      "Test Loss: 0.003450 \tTest Accuracy: 0.882033\n",
      "Test Loss: 0.003453 \tTest Accuracy: 0.883100\n",
      "Test Loss: 0.003453 \tTest Accuracy: 0.884167\n",
      "Test Loss: 0.003459 \tTest Accuracy: 0.885233\n",
      "Test Loss: 0.003460 \tTest Accuracy: 0.886300\n",
      "Test Loss: 0.003460 \tTest Accuracy: 0.887367\n",
      "Test Loss: 0.003463 \tTest Accuracy: 0.888433\n",
      "Test Loss: 0.003464 \tTest Accuracy: 0.889500\n",
      "Test Loss: 0.003465 \tTest Accuracy: 0.890567\n",
      "Test Loss: 0.003466 \tTest Accuracy: 0.891633\n",
      "Test Loss: 0.003468 \tTest Accuracy: 0.892700\n",
      "Test Loss: 0.003487 \tTest Accuracy: 0.893750\n",
      "Test Loss: 0.003488 \tTest Accuracy: 0.894817\n",
      "Test Loss: 0.003489 \tTest Accuracy: 0.895883\n",
      "Test Loss: 0.003492 \tTest Accuracy: 0.896950\n",
      "Test Loss: 0.003492 \tTest Accuracy: 0.898017\n",
      "Test Loss: 0.003493 \tTest Accuracy: 0.899083\n",
      "Test Loss: 0.003493 \tTest Accuracy: 0.900150\n",
      "Test Loss: 0.003494 \tTest Accuracy: 0.901217\n",
      "Test Loss: 0.003494 \tTest Accuracy: 0.902283\n",
      "Test Loss: 0.003495 \tTest Accuracy: 0.903350\n",
      "Test Loss: 0.003495 \tTest Accuracy: 0.904417\n",
      "Test Loss: 0.003495 \tTest Accuracy: 0.905483\n",
      "Test Loss: 0.003498 \tTest Accuracy: 0.906550\n",
      "Test Loss: 0.003499 \tTest Accuracy: 0.907617\n",
      "Test Loss: 0.003499 \tTest Accuracy: 0.908683\n",
      "Test Loss: 0.003500 \tTest Accuracy: 0.909750\n",
      "Test Loss: 0.003500 \tTest Accuracy: 0.910817\n",
      "Test Loss: 0.003500 \tTest Accuracy: 0.911883\n",
      "Test Loss: 0.003501 \tTest Accuracy: 0.912950\n",
      "Test Loss: 0.003502 \tTest Accuracy: 0.914017\n",
      "Test Loss: 0.003505 \tTest Accuracy: 0.915083\n",
      "Test Loss: 0.003505 \tTest Accuracy: 0.916150\n",
      "Test Loss: 0.003505 \tTest Accuracy: 0.917217\n",
      "Test Loss: 0.003509 \tTest Accuracy: 0.918283\n",
      "Test Loss: 0.003509 \tTest Accuracy: 0.919350\n",
      "Test Loss: 0.003510 \tTest Accuracy: 0.920417\n",
      "Test Loss: 0.003522 \tTest Accuracy: 0.921483\n",
      "Test Loss: 0.003523 \tTest Accuracy: 0.922550\n",
      "Test Loss: 0.003523 \tTest Accuracy: 0.923617\n",
      "Test Loss: 0.003523 \tTest Accuracy: 0.924683\n",
      "Test Loss: 0.003526 \tTest Accuracy: 0.925750\n",
      "Test Loss: 0.003526 \tTest Accuracy: 0.926817\n",
      "Test Loss: 0.003534 \tTest Accuracy: 0.927883\n",
      "Test Loss: 0.003537 \tTest Accuracy: 0.928950\n",
      "Test Loss: 0.003537 \tTest Accuracy: 0.930017\n",
      "Test Loss: 0.003542 \tTest Accuracy: 0.931083\n",
      "Test Loss: 0.003542 \tTest Accuracy: 0.932150\n",
      "Test Loss: 0.003543 \tTest Accuracy: 0.933217\n",
      "Test Loss: 0.003543 \tTest Accuracy: 0.934283\n",
      "Test Loss: 0.003548 \tTest Accuracy: 0.935350\n",
      "Test Loss: 0.003549 \tTest Accuracy: 0.936417\n",
      "Test Loss: 0.003549 \tTest Accuracy: 0.937483\n",
      "Test Loss: 0.003550 \tTest Accuracy: 0.938550\n",
      "Test Loss: 0.003550 \tTest Accuracy: 0.939617\n",
      "Test Loss: 0.003559 \tTest Accuracy: 0.940683\n",
      "Test Loss: 0.003562 \tTest Accuracy: 0.941750\n",
      "Test Loss: 0.003603 \tTest Accuracy: 0.942800\n",
      "Test Loss: 0.003627 \tTest Accuracy: 0.943850\n",
      "Test Loss: 0.003629 \tTest Accuracy: 0.944917\n",
      "Test Loss: 0.003638 \tTest Accuracy: 0.945983\n",
      "Test Loss: 0.003638 \tTest Accuracy: 0.947050\n",
      "Test Loss: 0.003673 \tTest Accuracy: 0.948100\n",
      "Test Loss: 0.003674 \tTest Accuracy: 0.949167\n",
      "Test Loss: 0.003686 \tTest Accuracy: 0.950217\n",
      "Test Loss: 0.003686 \tTest Accuracy: 0.951283\n",
      "Test Loss: 0.003686 \tTest Accuracy: 0.952350\n",
      "Test Loss: 0.003687 \tTest Accuracy: 0.953417\n",
      "Test Loss: 0.003687 \tTest Accuracy: 0.954483\n",
      "Test Loss: 0.003691 \tTest Accuracy: 0.955550\n",
      "Test Loss: 0.003692 \tTest Accuracy: 0.956617\n",
      "Test Loss: 0.003692 \tTest Accuracy: 0.957683\n",
      "Test Loss: 0.003694 \tTest Accuracy: 0.958750\n",
      "Test Loss: 0.003694 \tTest Accuracy: 0.959817\n",
      "Test Loss: 0.003695 \tTest Accuracy: 0.960883\n",
      "Test Loss: 0.003695 \tTest Accuracy: 0.961950\n",
      "Test Loss: 0.003695 \tTest Accuracy: 0.963017\n",
      "Test Loss: 0.003710 \tTest Accuracy: 0.964067\n",
      "Test Loss: 0.003710 \tTest Accuracy: 0.965133\n",
      "Test Loss: 0.003712 \tTest Accuracy: 0.966200\n",
      "Test Loss: 0.003712 \tTest Accuracy: 0.967267\n",
      "Test Loss: 0.003712 \tTest Accuracy: 0.968333\n",
      "Test Loss: 0.003718 \tTest Accuracy: 0.969400\n",
      "Test Loss: 0.003718 \tTest Accuracy: 0.970467\n",
      "Test Loss: 0.003719 \tTest Accuracy: 0.971533\n",
      "Test Loss: 0.003720 \tTest Accuracy: 0.972600\n",
      "Test Loss: 0.003720 \tTest Accuracy: 0.973667\n",
      "Test Loss: 0.003791 \tTest Accuracy: 0.974717\n",
      "Test Loss: 0.003792 \tTest Accuracy: 0.975783\n",
      "Test Loss: 0.003793 \tTest Accuracy: 0.976850\n",
      "Test Loss: 0.003793 \tTest Accuracy: 0.977917\n",
      "Test Loss: 0.003794 \tTest Accuracy: 0.978983\n",
      "Test Loss: 0.003794 \tTest Accuracy: 0.980050\n",
      "Test Loss: 0.003794 \tTest Accuracy: 0.981117\n",
      "Test Loss: 0.003794 \tTest Accuracy: 0.982183\n",
      "Test Loss: 0.003797 \tTest Accuracy: 0.983250\n",
      "Test Loss: 0.003797 \tTest Accuracy: 0.984317\n",
      "Test Loss: 0.003798 \tTest Accuracy: 0.985383\n",
      "Test Loss: 0.003798 \tTest Accuracy: 0.986450\n",
      "Test Loss: 0.003805 \tTest Accuracy: 0.987517\n",
      "Test Loss: 0.003805 \tTest Accuracy: 0.988583\n",
      "Test Loss: 0.003810 \tTest Accuracy: 0.989650\n",
      "Test Loss: 0.003811 \tTest Accuracy: 0.990717\n",
      "Test Loss: 0.003811 \tTest Accuracy: 0.991783\n",
      "Test Loss: 0.003811 \tTest Accuracy: 0.992850\n",
      "Test Loss: 0.003811 \tTest Accuracy: 0.993917\n",
      "Test Loss: 0.003812 \tTest Accuracy: 0.994983\n",
      "Test Loss: 0.003829 \tTest Accuracy: 0.996033\n",
      "Test Loss: 0.003833 \tTest Accuracy: 0.997100\n",
      "Test Loss: 0.003855 \tTest Accuracy: 0.998150\n",
      "Test Loss: 0.003855 \tTest Accuracy: 0.998683\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_loss = 0.0\n",
    "test_accuracy = 0.0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_trues, y_preds = [], []\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += (prediction == labels).sum().item()\n",
    "        y_trues.extend(labels)\n",
    "        y_preds.extend(prediction)\n",
    "    print('Test Loss: {:.6f} \\tTest Accuracy: {:.6f}'.format(test_loss/len(testloader.dataset), test_accuracy/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.998684516831351,\n",
      "  \"recall\": 0.9986833333333334,\n",
      "  \"f1\": 0.9986832272223732,\n",
      "  \"num_samples\": 60000.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classes = [i for i in range(10)]\n",
    "\n",
    "performance = get_metrics(y_trues, y_preds, classes)\n",
    "\n",
    "print(json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save model\n",
    "dir = Path(\"CNN\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), Path(dir, \"model.pt\"))\n",
    "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
    "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making individual inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcDklEQVR4nO3df3DU9b3v8dcCyQqaLIaQXyVgAAUrEK9U0hRFlAxJOsPw63TAH3PA4+ARgy2i1ZuOirSdSYtnrKND8c69FepcwR8zQkaOpUeDCaMGekG4HNqaEm5aYkmCcie7IZgQyOf+wXXrSoJ+l928s8vzMfOdIbvfT/bt19Un3+zuNz7nnBMAAANsiPUAAIDLEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmhlkP8FW9vb06fvy40tLS5PP5rMcBAHjknFNHR4fy8vI0ZEj/5zmDLkDHjx9Xfn6+9RgAgEvU3NysMWPG9Hv/oAtQWlqaJOkWfV/DlGI8DQDAq7Pq0ft6O/z/8/7ELUAbNmzQM888o9bWVhUWFuqFF17QjBkzvnbdFz92G6YUDfMRIABIOP//CqNf9zJKXN6E8Nprr2nNmjVau3atPvroIxUWFqq0tFQnTpyIx8MBABJQXAL07LPPasWKFbr33nv17W9/Wy+++KJGjBihl156KR4PBwBIQDEP0JkzZ7R//36VlJT840GGDFFJSYnq6+sv2L+7u1uhUChiAwAkv5gH6LPPPtO5c+eUnZ0dcXt2drZaW1sv2L+qqkqBQCC88Q44ALg8mH8QtbKyUsFgMLw1NzdbjwQAGAAxfxdcZmamhg4dqra2tojb29ralJOTc8H+fr9ffr8/1mMAAAa5mJ8Bpaamavr06aqpqQnf1tvbq5qaGhUXF8f64QAACSounwNas2aNli1bpu985zuaMWOGnnvuOXV2duree++Nx8MBABJQXAK0ZMkSffrpp3rqqafU2tqqG2+8UTt37rzgjQkAgMuXzznnrIf4slAopEAgoNmaz5UQACABnXU9qlW1gsGg0tPT+93P/F1wAIDLEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBimPUAQDz4pt8Q1breVO//Sfx99pWe1/zxoV97XtPjznlek4zmHP4nz2uunN8S1WP1dnVFtQ7fDGdAAAATBAgAYCLmAXr66afl8/kitsmTJ8f6YQAACS4urwHdcMMNevfdd//xIMN4qQkAECkuZRg2bJhycnLi8a0BAEkiLq8BHTlyRHl5eRo/frzuvvtuHTt2rN99u7u7FQqFIjYAQPKLeYCKioq0efNm7dy5Uxs3blRTU5NuvfVWdXR09Ll/VVWVAoFAeMvPz4/1SACAQSjmASovL9cPfvADTZs2TaWlpXr77bfV3t6u119/vc/9KysrFQwGw1tzc3OsRwIADEJxf3fAyJEjdd1116mxsbHP+/1+v/x+f7zHAAAMMnH/HNCpU6d09OhR5ebmxvuhAAAJJOYBevTRR1VXV6e//vWv+vDDD7Vw4UINHTpUd955Z6wfCgCQwGL+I7hPPvlEd955p06ePKnRo0frlltu0Z49ezR69OhYPxQAIIH5nHPOeogvC4VCCgQCmq35GuZLsR4HMeaKCz2vObI81fOaX92x1fMaSUrxnfW8pmR43+/wvJghUfzwoVe9ntfgvBs//Jeo1hWsPO55zbnPTkb1WMnkrOtRraoVDAaVnp7e735cCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBH3X0gHfJn7+f/1vObjyW/GYRJcTg5+76Wo1pUWPeh5jf/fuRjpN8UZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwNWwMqL/X5ntfNDn2c/Snvsvvec2/vL3C+wP5vC+Ri2JNlL570188r9l0zX/EYRIkM86AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXIwUA2rsL/Z5XrPw9TvjMEnffGd6PK+5tmlvHCax1Z45yvOad/ekeV5TMrzD85po3PGfS6Jal/7eHz2v6Y3qkS5PnAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GCkGlOs543nNuYbGOEyCi2lbdJ3nNVNTq6N4JH8Ua7w7fjwjqnVXnf4/MZ4EX8YZEADABAECAJjwHKDdu3dr3rx5ysvLk8/n0/bt2yPud87pqaeeUm5uroYPH66SkhIdOXIkVvMCAJKE5wB1dnaqsLBQGzZs6PP+9evX6/nnn9eLL76ovXv36sorr1Rpaam6uroueVgAQPLw/CaE8vJylZeX93mfc07PPfecnnjiCc2fP1+S9PLLLys7O1vbt2/X0qVLL21aAEDSiOlrQE1NTWptbVVJSUn4tkAgoKKiItXX1/e5pru7W6FQKGIDACS/mAaotbVVkpSdnR1xe3Z2dvi+r6qqqlIgEAhv+fn5sRwJADBImb8LrrKyUsFgMLw1NzdbjwQAGAAxDVBOTo4kqa2tLeL2tra28H1f5ff7lZ6eHrEBAJJfTANUUFCgnJwc1dTUhG8LhULau3eviouLY/lQAIAE5/ldcKdOnVJj4z8ujdLU1KSDBw8qIyNDY8eO1erVq/Xzn/9c1157rQoKCvTkk08qLy9PCxYsiOXcAIAE5zlA+/bt0+233x7+es2aNZKkZcuWafPmzXrsscfU2dmp+++/X+3t7brlllu0c+dOXXHFFbGbGgCQ8HzOOWc9xJeFQiEFAgHN1nwN86VYjwMktE9XRvej78n3fOx5zaZr/iOqxxoICwvLolp37rOTMZ7k8nDW9ahW1QoGgxd9Xd/8XXAAgMsTAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHj+dQwALt2JVd/zvGbZyrc9r7kn/d88r5GktCGpUa0bCD/79CbPa1z3mThMgkvFGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKLkWJADb1hkuc1f7n3as9rbrvlsOc1A2lH/gue1/SqN4pHGriLijb2nPW8ZsnGRzyvGbutzfOa3o6jntcg/jgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDFSRM3NvNHzmuWbtnleM//KzzyvGfyS7+9+P2xc4nnNt375oec15zyvwGCVfP8VAAASAgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRYkANlfO8ZkgS/j0pxTfU85oe74duQO283vuFZm+9u8LzmsArezyvweCUfP9lAwASAgECAJjwHKDdu3dr3rx5ysvLk8/n0/bt2yPuX758uXw+X8RWVlYWq3kBAEnCc4A6OztVWFioDRs29LtPWVmZWlpawtvWrVsvaUgAQPLx/CaE8vJylZeXX3Qfv9+vnJycqIcCACS/uLwGVFtbq6ysLE2aNEkrV67UyZMn+923u7tboVAoYgMAJL+YB6isrEwvv/yyampq9Mtf/lJ1dXUqLy/XuXN9/yb3qqoqBQKB8Jafnx/rkQAAg1DMPwe0dOnS8J+nTp2qadOmacKECaqtrdWcOXMu2L+yslJr1qwJfx0KhYgQAFwG4v427PHjxyszM1ONjY193u/3+5Wenh6xAQCSX9wD9Mknn+jkyZPKzc2N90MBABKI5x/BnTp1KuJspqmpSQcPHlRGRoYyMjK0bt06LV68WDk5OTp69Kgee+wxTZw4UaWlpTEdHACQ2DwHaN++fbr99tvDX3/x+s2yZcu0ceNGHTp0SL/97W/V3t6uvLw8zZ07Vz/72c/k9/tjNzUAIOF5DtDs2bPlXP9XRfz9739/SQMhcfg+OOh5zW8WeL8qxn9dPsrzmrG/P+N5jSQN/fxsVOsGqyP3pUS17uOyjTGeBLgQ14IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiZj/Sm7gYs796S+e14x/LA6DXCauPzI6uoXeL1oOeMYZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggouRAkmsbdFE6xGAfnEGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkScbn93te0/6D/xLVY11d/UfPa3o7OqJ6LEgtj3zP85rqH66P8tG8P48ArzgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDHSQaxr3gzPawKPHvO8pm7iC57XSNLC/3Wn90UNyXcx0mG5OZ7X/P2fxnte89pD/+Z5Td6wgbuoaNu5bs9rUj53cZgEiYIzIACACQIEADDhKUBVVVW6+eablZaWpqysLC1YsEANDQ0R+3R1damiokKjRo3SVVddpcWLF6utrS2mQwMAEp+nANXV1amiokJ79uzRO++8o56eHs2dO1ednZ3hfR5++GG99dZbeuONN1RXV6fjx49r0aJFMR8cAJDYPL0JYefOnRFfb968WVlZWdq/f79mzZqlYDCo3/zmN9qyZYvuuOMOSdKmTZt0/fXXa8+ePfrud78bu8kBAAntkl4DCgaDkqSMjAxJ0v79+9XT06OSkpLwPpMnT9bYsWNVX1/f5/fo7u5WKBSK2AAAyS/qAPX29mr16tWaOXOmpkyZIklqbW1VamqqRo4cGbFvdna2Wltb+/w+VVVVCgQC4S0/Pz/akQAACSTqAFVUVOjw4cN69dVXL2mAyspKBYPB8Nbc3HxJ3w8AkBii+iDqqlWrtGPHDu3evVtjxowJ356Tk6MzZ86ovb094iyora1NOTl9f1jP7/fL7x+4D8sBAAYHT2dAzjmtWrVK27Zt065du1RQUBBx//Tp05WSkqKamprwbQ0NDTp27JiKi4tjMzEAICl4OgOqqKjQli1bVF1drbS0tPDrOoFAQMOHD1cgENB9992nNWvWKCMjQ+np6XrooYdUXFzMO+AAABE8BWjjxo2SpNmzZ0fcvmnTJi1fvlyS9Ktf/UpDhgzR4sWL1d3drdLSUv3617+OybAAgOThc84NqqsBhkIhBQIBzdZ8DfOlWI9j6rZDn3te88iow3GYpG/Xv/uv3hedSr5/p0u/1/dHDC5mXdYBz2t61et5TbSW/bXU85rGTZM8rxn1P7wfOwx+Z12PalWtYDCo9PT0fvfjWnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEdVvRAUk6c8l/816hATm/e9+9V3ef3Pwir3/7HmNJE1cccTzmlGdXNka3nAGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkg9iuH870vOblB2d4XvO/Z77keU2y+p+hfM9rWnpGel7z0kfe/91O/O/nPK8Z/8FBz2skqTeqVYA3nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GOkgNrT2I89rCv4wwvOa6T/8kec1kvTbf33O85opqT7Pa+74zyWe1wRrczyvkaRxr/3d85qzTX/zvOZa7fe8Bkg2nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ8zjlnPcSXhUIhBQIBzdZ8DfOlWI8DAPDorOtRraoVDAaVnp7e736cAQEATBAgAIAJTwGqqqrSzTffrLS0NGVlZWnBggVqaGiI2Gf27Nny+XwR2wMPPBDToQEAic9TgOrq6lRRUaE9e/bonXfeUU9Pj+bOnavOzs6I/VasWKGWlpbwtn79+pgODQBIfJ5+I+rOnTsjvt68ebOysrK0f/9+zZo1K3z7iBEjlJMT3W+kBABcHi7pNaBgMChJysjIiLj9lVdeUWZmpqZMmaLKykqdPn263+/R3d2tUCgUsQEAkp+nM6Av6+3t1erVqzVz5kxNmTIlfPtdd92lcePGKS8vT4cOHdLjjz+uhoYGvfnmm31+n6qqKq1bty7aMQAACSrqzwGtXLlSv/vd7/T+++9rzJgx/e63a9cuzZkzR42NjZowYcIF93d3d6u7uzv8dSgUUn5+Pp8DAoAE9U0/BxTVGdCqVau0Y8cO7d69+6LxkaSioiJJ6jdAfr9ffr8/mjEAAAnMU4Ccc3rooYe0bds21dbWqqCg4GvXHDx4UJKUm5sb1YAAgOTkKUAVFRXasmWLqqurlZaWptbWVklSIBDQ8OHDdfToUW3ZskXf//73NWrUKB06dEgPP/ywZs2apWnTpsXlHwAAkJg8vQbk8/n6vH3Tpk1avny5mpubdc899+jw4cPq7OxUfn6+Fi5cqCeeeOKiPwf8Mq4FBwCJLS6vAX1dq/Lz81VXV+flWwIALlNcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKY9QBf5ZyTJJ1Vj+SMhwEAeHZWPZL+8f/z/gy6AHV0dEiS3tfbxpMAAC5FR0eHAoFAv/f73NclaoD19vbq+PHjSktLk8/ni7gvFAopPz9fzc3NSk9PN5rQHsfhPI7DeRyH8zgO5w2G4+CcU0dHh/Ly8jRkSP+v9Ay6M6AhQ4ZozJgxF90nPT39sn6CfYHjcB7H4TyOw3kch/Osj8PFzny+wJsQAAAmCBAAwERCBcjv92vt2rXy+/3Wo5jiOJzHcTiP43Aex+G8RDoOg+5NCACAy0NCnQEBAJIHAQIAmCBAAAATBAgAYCJhArRhwwZdc801uuKKK1RUVKQ//OEP1iMNuKefflo+ny9imzx5svVYcbd7927NmzdPeXl58vl82r59e8T9zjk99dRTys3N1fDhw1VSUqIjR47YDBtHX3ccli9ffsHzo6yszGbYOKmqqtLNN9+stLQ0ZWVlacGCBWpoaIjYp6urSxUVFRo1apSuuuoqLV68WG1tbUYTx8c3OQ6zZ8++4PnwwAMPGE3ct4QI0GuvvaY1a9Zo7dq1+uijj1RYWKjS0lKdOHHCerQBd8MNN6ilpSW8vf/++9YjxV1nZ6cKCwu1YcOGPu9fv369nn/+eb344ovau3evrrzySpWWlqqrq2uAJ42vrzsOklRWVhbx/Ni6desAThh/dXV1qqio0J49e/TOO++op6dHc+fOVWdnZ3ifhx9+WG+99ZbeeOMN1dXV6fjx41q0aJHh1LH3TY6DJK1YsSLi+bB+/XqjifvhEsCMGTNcRUVF+Otz5865vLw8V1VVZTjVwFu7dq0rLCy0HsOUJLdt27bw1729vS4nJ8c988wz4dva29ud3+93W7duNZhwYHz1ODjn3LJly9z8+fNN5rFy4sQJJ8nV1dU5587/u09JSXFvvPFGeJ8///nPTpKrr6+3GjPuvnocnHPutttucz/60Y/shvoGBv0Z0JkzZ7R//36VlJSEbxsyZIhKSkpUX19vOJmNI0eOKC8vT+PHj9fdd9+tY8eOWY9kqqmpSa2trRHPj0AgoKKiosvy+VFbW6usrCxNmjRJK1eu1MmTJ61HiqtgMChJysjIkCTt379fPT09Ec+HyZMna+zYsUn9fPjqcfjCK6+8oszMTE2ZMkWVlZU6ffq0xXj9GnQXI/2qzz77TOfOnVN2dnbE7dnZ2fr444+NprJRVFSkzZs3a9KkSWppadG6det066236vDhw0pLS7Mez0Rra6sk9fn8+OK+y0VZWZkWLVqkgoICHT16VD/5yU9UXl6u+vp6DR061Hq8mOvt7dXq1as1c+ZMTZkyRdL550NqaqpGjhwZsW8yPx/6Og6SdNddd2ncuHHKy8vToUOH9Pjjj6uhoUFvvvmm4bSRBn2A8A/l5eXhP0+bNk1FRUUaN26cXn/9dd13332Gk2EwWLp0afjPU6dO1bRp0zRhwgTV1tZqzpw5hpPFR0VFhQ4fPnxZvA56Mf0dh/vvvz/856lTpyo3N1dz5szR0aNHNWHChIEes0+D/kdwmZmZGjp06AXvYmlra1NOTo7RVIPDyJEjdd1116mxsdF6FDNfPAd4flxo/PjxyszMTMrnx6pVq7Rjxw699957Eb++JScnR2fOnFF7e3vE/sn6fOjvOPSlqKhIkgbV82HQByg1NVXTp09XTU1N+Lbe3l7V1NSouLjYcDJ7p06d0tGjR5Wbm2s9ipmCggLl5OREPD9CoZD27t172T8/PvnkE508eTKpnh/OOa1atUrbtm3Trl27VFBQEHH/9OnTlZKSEvF8aGho0LFjx5Lq+fB1x6EvBw8elKTB9XywfhfEN/Hqq686v9/vNm/e7P70pz+5+++/340cOdK1trZajzagHnnkEVdbW+uamprcBx984EpKSlxmZqY7ceKE9Whx1dHR4Q4cOOAOHDjgJLlnn33WHThwwP3tb39zzjn3i1/8wo0cOdJVV1e7Q4cOufnz57uCggL3+eefG08eWxc7Dh0dHe7RRx919fX1rqmpyb377rvupptuctdee63r6uqyHj1mVq5c6QKBgKutrXUtLS3h7fTp0+F9HnjgATd27Fi3a9cut2/fPldcXOyKi4sNp469rzsOjY2N7qc//anbt2+fa2pqctXV1W78+PFu1qxZxpNHSogAOefcCy+84MaOHetSU1PdjBkz3J49e6xHGnBLlixxubm5LjU11X3rW99yS5YscY2NjdZjxd17773nJF2wLVu2zDl3/q3YTz75pMvOznZ+v9/NmTPHNTQ02A4dBxc7DqdPn3Zz5851o0ePdikpKW7cuHFuxYoVSfeXtL7++SW5TZs2hff5/PPP3YMPPuiuvvpqN2LECLdw4ULX0tJiN3QcfN1xOHbsmJs1a5bLyMhwfr/fTZw40f34xz92wWDQdvCv4NcxAABMDPrXgAAAyYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMPH/AOet0kpmDjLBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Make predictions for a single image\n",
    "image, label = testset[7]\n",
    "plt.imshow(image.numpy().squeeze());\n",
    "plt.show()\n",
    "\n",
    "#reshape image to (1, 1, 28, 28) to match the input shape of the model\n",
    "image = image.reshape(1, 1, 28, 28)\n",
    "\n",
    "# Turn off gradients for validation, saves memory and computations\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred_probs = model(image)\n",
    "    ps = torch.exp(pred_probs)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    print(top_class.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57dbe44eb74a19d18f388e4d9fafc4d32a78d1722d572d14a517bc61ad3dae60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
